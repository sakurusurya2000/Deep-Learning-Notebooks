{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_rnn_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "v9ZgzXdmiWIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Char RNN\n",
        "\n",
        "In this notebook, we will go through basics of Char-RNN and use different datasets to create different RNNs.\n",
        "\n",
        "Here we will use [PyTorch](http://pytorch.org/tutorials/  \"PyTorch Tutorial\").\n",
        "\n",
        "\n",
        "Hey yo, but how to see what CNN sees?\n",
        "\n",
        "Everything is explained in-detail in [blog post](). This is notebook which replicates the result of blog and runs in colab. Enjoy!\n",
        "\n",
        "\n",
        "#### Run in Colab\n",
        "\n",
        "You can run this notebook in google colab.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dudeperf3ct/DL_notebooks/blob/master/RNN/char_rnn_pytorch.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Here are some other very interesting results, [Cooking-Recipe](https://gist.github.com/nylki/1efbaa36635956d35bcc), [Obama-RNN](https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0), [Bible-RNN](https://twitter.com/RNN_Bible), [Folk-music](https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music), [Learning Holiness](https://cpury.github.io/learning-holiness/), [AI Weirdness](http://aiweirdness.com/), [Auto-Generating Clickbait](https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/)."
      ]
    },
    {
      "metadata": {
        "id": "xOND0u0Rp3R6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ]
    },
    {
      "metadata": {
        "id": "Ux9Ideiip5ym",
        "colab_type": "code",
        "outputId": "90204890-fc2f-41aa-d4c6-c8bc96285297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "! wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\" -P {'data/'}\n",
        "! wget \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\" -P {'data/'}\n",
        "! wget \"http://www.gutenberg.org/files/31100/31100.txt\" -P {'data/'}\n",
        "! wget \"http://www.gutenberg.org/cache/epub/29765/pg29765.txt\" -P {'data/'}\n",
        "! wget \"https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt\" -P {'data/'}\n",
        "! wget \"https://raw.githubusercontent.com/mcleonard/pytorch-charRNN/master/data/anna.txt\" -P {'data/'}\n",
        "! wget \"https://raw.githubusercontent.com/samim23/obama-rnn/master/input.txt\" -P {'data/obama/'}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-17 10:28:25--  https://raw.githubusercontent.com/samim23/obama-rnn/master/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4250014 (4.1M) [text/plain]\n",
            "Saving to: ‘data/obama/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   4.05M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-02-17 10:28:25 (34.2 MB/s) - ‘data/obama/input.txt’ saved [4250014/4250014]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AVq3IFekiRC2",
        "colab_type": "code",
        "outputId": "26fcedb1-3255-45a2-9c98-56778f62c740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print (device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KiStxFWCgr9a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Enchancements\n",
        "\n",
        "To further improve the results, here are some things that can be done:\n",
        "\n",
        "1. Instead of converting all input text to lower we can use capitilization as it is.\n",
        "\n",
        "2. To use all data, we could create batch generator to feed all batches instead of loading everything on RAM"
      ]
    },
    {
      "metadata": {
        "id": "X8cg7-Pngilx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ShakespeareRNN"
      ]
    },
    {
      "metadata": {
        "id": "lXc3aOq8iZP6",
        "colab_type": "code",
        "outputId": "accd3638-5ab2-40c8-f9f3-b314ca81569e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/input.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2J8wSUiwc7I",
        "colab_type": "code",
        "outputId": "b9e67a6b-d8e3-4f78-c0a2-dcc945d5a862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:515394]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {'C', 'a', 'S', 'T', 'm', '.', 'Y', 'x', 'K', 'b', 'h', 'z', 'w', 's', 'k', 'M', 'L', 'N', 't', 'R', '&', 'Z', 'D', 'q', 'F', ' ', 'd', 'O', 'u', 'j', '-', 'I', ':', 'A', 'c', 'g', 'l', 'Q', 'i', 'e', 'E', 'B', 'y', \"'\", 'f', '?', 'n', ',', '!', 'P', ';', 'X', 'J', '3', 'V', 'r', 'W', 'p', 'H', '$', 'G', 'v', 'U', '\\n', 'o'}\n",
            "Length of Unique characters: 65\n",
            "Number of characters in data: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p870Fa84iZTM",
        "colab_type": "code",
        "outputId": "973d87ae-7956-4d86-890a-4bddf55c0fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{'C': 0, 'a': 1, 'S': 2, 'T': 3, 'm': 4, '.': 5, 'Y': 6, 'x': 7, 'K': 8, 'b': 9, 'h': 10, 'z': 11, 'w': 12, 's': 13, 'k': 14, 'M': 15, 'L': 16, 'N': 17, 't': 18, 'R': 19, '&': 20, 'Z': 21, 'D': 22, 'q': 23, 'F': 24, ' ': 25, 'd': 26, 'O': 27, 'u': 28, 'j': 29, '-': 30, 'I': 31, ':': 32, 'A': 33, 'c': 34, 'g': 35, 'l': 36, 'Q': 37, 'i': 38, 'e': 39, 'E': 40, 'B': 41, 'y': 42, \"'\": 43, 'f': 44, '?': 45, 'n': 46, ',': 47, '!': 48, 'P': 49, ';': 50, 'X': 51, 'J': 52, '3': 53, 'V': 54, 'r': 55, 'W': 56, 'p': 57, 'H': 58, '$': 59, 'G': 60, 'v': 61, 'U': 62, '\\n': 63, 'o': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Olm5nu3WUmZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cofisUDfUmch",
        "colab_type": "code",
        "outputId": "88f6b689-975a-4b7f-9454-48f786e86262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[24, 38, 55, 13, 18, 25, 0, 38, 18, 38, 11, 39, 46, 32, 63, 41, 39, 44, 64, 55, 39, 25, 12, 39, 25, 57, 55, 64, 34, 39, 39, 26, 25, 1, 46, 42, 25, 44, 28, 55, 18, 10, 39, 55, 47, 25, 10, 39, 1, 55, 25, 4, 39, 25, 13, 57, 39, 1, 14, 5, 63, 63, 33, 36, 36, 32, 63, 2, 57, 39, 1, 14, 47, 25, 13, 57, 39, 1, 14, 5, 63, 63, 24, 38, 55, 13, 18, 25, 0, 38, 18, 38, 11, 39, 46, 32, 63, 6, 64, 28] 100 5153\n",
            "[38, 55, 13, 18, 25, 0, 38, 18, 38, 11, 39, 46, 32, 63, 41, 39, 44, 64, 55, 39, 25, 12, 39, 25, 57, 55, 64, 34, 39, 39, 26, 25, 1, 46, 42, 25, 44, 28, 55, 18, 10, 39, 55, 47, 25, 10, 39, 1, 55, 25, 4, 39, 25, 13, 57, 39, 1, 14, 5, 63, 63, 33, 36, 36, 32, 63, 2, 57, 39, 1, 14, 47, 25, 13, 57, 39, 1, 14, 5, 63, 63, 24, 38, 55, 13, 18, 25, 0, 38, 18, 38, 11, 39, 46, 32, 63, 6, 64, 28, 25] 100 5153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7x2-ybzSUmWD",
        "colab_type": "code",
        "outputId": "d9772b49-d92d-4e6d-e91b-609c5035a863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "Output: irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Klrr279MWdfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COG83LIHVBwb",
        "colab_type": "code",
        "outputId": "ac4a31a2-7fb7-4f5d-f994-415bee3a8457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (5153, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYz0MkROVBtZ",
        "colab_type": "code",
        "outputId": "6d33d2b7-efe2-4400-b8e1-8ab77c7d52c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[38 55 13 18 25  0 38 18 38 11 39 46 32 63 41 39 44 64 55 39 25 12 39 25\n",
            " 57 55 64 34 39 39 26 25  1 46 42 25 44 28 55 18 10 39 55 47 25 10 39  1\n",
            " 55 25  4 39 25 13 57 39  1 14  5 63 63 33 36 36 32 63  2 57 39  1 14 47\n",
            " 25 13 57 39  1 14  5 63 63 24 38 55 13 18 25  0 38 18 38 11 39 46 32 63\n",
            "  6 64 28 25] (5153, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lLZxc9GSVE9_",
        "colab_type": "code",
        "outputId": "581034a6-f292-4a58-f445-0ccd127a7982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.05)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (4895, 100, 65) (4895, 100)\n",
            "Validation: (258, 100, 65) (258, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w73RMYqjN3mq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CharRNN PyTorch Model\n",
        "\n",
        "Code adapted from : [Link](https://github.com/mcleonard/pytorch-charRNN/blob/master/TorchRNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "w9LLYPrmVGwq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "  \n",
        "    def __init__(self, batch_size=128, n_hidden=512, n_layers=2, drop_prob=0.5):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "      \n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.lstm = nn.LSTM(vocab_size, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self, x, hc):\n",
        "        ''' Forward pass through the network '''\n",
        "        \n",
        "        x, (h, c) = self.lstm(x, hc)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Stack up LSTM outputs\n",
        "        x = x.view(x.size()[0]*x.size()[1], self.n_hidden)\n",
        "        \n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x, (h, c)\n",
        "    \n",
        "    def predict(self, char, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "        \n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        if h is None:\n",
        "            h = self.init_hidden(1)\n",
        "        \n",
        "        x = np.array([[char2id[char]]])\n",
        "        x = to_categorical(x, num_classes=vocab_size)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            h = tuple([Variable(each.data) for each in h])\n",
        "            inputs = Variable(torch.from_numpy(x))\n",
        "        inputs = inputs.to(device)\n",
        "        \n",
        "        out, h = self.forward(inputs, h)\n",
        "        p = F.softmax(out).data\n",
        "        p = p.to(device)\n",
        "        \n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(vocab_size)\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.cpu().numpy().squeeze()\n",
        "        \n",
        "        p = p.cpu().numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "            \n",
        "        return id2char[char], h\n",
        "    \n",
        "    def init_weights(self):\n",
        "        ''' Initialize weights for fully connected layer '''\n",
        "      \n",
        "        # Set bias tensor to all zeros\n",
        "        self.fc.bias.data.fill_(0)\n",
        "        # FC weights as random uniform\n",
        "        self.fc.weight.data.uniform_(-1, 1)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        return (Variable(weight.new(self.n_layers, batch_size, self.n_hidden).zero_()),\n",
        "                Variable(weight.new(self.n_layers, batch_size, self.n_hidden).zero_()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQEX8VVoXMiD",
        "colab_type": "code",
        "outputId": "227f1f3d-75fa-4376-d1b7-7a5eb3b2f3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(65, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "87cufvI9XLYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwLbqNUTVWY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, train_x, train_y, val_x, val_y, opt, criterion, epochs=25, batch_size=128, maxlen=100, clip=5, print_every=10):\n",
        "    \n",
        "    net.train()\n",
        "    counter = 0\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for k in range(0, train_x.shape[0]-batch_size, batch_size):\n",
        "            \n",
        "            counter += 1\n",
        "            # batch data and convert to torch tensors\n",
        "            x, y = train_x[k : k+batch_size], train_y[k : k+batch_size]\n",
        "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            \n",
        "            inputs, targets = Variable(x), Variable(y)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            #print (counter, inputs.shape, targets.shape)\n",
        "            \n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([Variable(each.data) for each in h])\n",
        "\n",
        "            net.zero_grad()\n",
        "            output, h = net.forward(inputs, h)\n",
        "            loss = criterion(output, targets.view(batch_size*maxlen))\n",
        "            loss.backward()\n",
        "            \n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "\n",
        "            opt.step()\n",
        "            \n",
        "            if counter % print_every == 0:\n",
        "                \n",
        "                # Get validation loss\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                \n",
        "                for k in range(0, val_x.shape[0]-batch_size, batch_size):\n",
        "                  \n",
        "                    # One-hot encode our data and make them Torch tensors\n",
        "                    x, y = val_x[k : k+batch_size], val_y[k : k+batch_size]\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "                    \n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    with torch.no_grad():\n",
        "                        val_h = tuple([Variable(each.data) for each in val_h])\n",
        "                        inputs, targets = Variable(x), Variable(y)\n",
        "                    \n",
        "                    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                    output, val_h = net.forward(inputs, val_h)\n",
        "                    val_loss = criterion(output, targets.view(batch_size*maxlen))\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVDIX8iTP1c7",
        "colab_type": "code",
        "outputId": "fe9efe08-1e17-42d0-d4ca-ed6d03836af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1762
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.4232... Val Loss: 3.4138\n",
            "Epoch: 1/25... Step: 20... Loss: 3.3019... Val Loss: 3.2861\n",
            "Epoch: 1/25... Step: 30... Loss: 3.1572... Val Loss: 3.1254\n",
            "Epoch: 2/25... Step: 40... Loss: 2.9588... Val Loss: 2.9408\n",
            "Epoch: 2/25... Step: 50... Loss: 2.7755... Val Loss: 2.7430\n",
            "Epoch: 2/25... Step: 60... Loss: 2.6318... Val Loss: 2.6211\n",
            "Epoch: 2/25... Step: 70... Loss: 2.5555... Val Loss: 2.5357\n",
            "Epoch: 3/25... Step: 80... Loss: 2.4869... Val Loss: 2.4701\n",
            "Epoch: 3/25... Step: 90... Loss: 2.4321... Val Loss: 2.4182\n",
            "Epoch: 3/25... Step: 100... Loss: 2.3904... Val Loss: 2.3831\n",
            "Epoch: 3/25... Step: 110... Loss: 2.3869... Val Loss: 2.3444\n",
            "Epoch: 4/25... Step: 120... Loss: 2.3362... Val Loss: 2.3079\n",
            "Epoch: 4/25... Step: 130... Loss: 2.3136... Val Loss: 2.2781\n",
            "Epoch: 4/25... Step: 140... Loss: 2.2792... Val Loss: 2.2485\n",
            "Epoch: 4/25... Step: 150... Loss: 2.2742... Val Loss: 2.2318\n",
            "Epoch: 5/25... Step: 160... Loss: 2.2793... Val Loss: 2.2047\n",
            "Epoch: 5/25... Step: 170... Loss: 2.1836... Val Loss: 2.1795\n",
            "Epoch: 5/25... Step: 180... Loss: 2.1870... Val Loss: 2.1688\n",
            "Epoch: 5/25... Step: 190... Loss: 2.1795... Val Loss: 2.1449\n",
            "Epoch: 6/25... Step: 200... Loss: 2.1253... Val Loss: 2.1290\n",
            "Epoch: 6/25... Step: 210... Loss: 2.1215... Val Loss: 2.1054\n",
            "Epoch: 6/25... Step: 220... Loss: 2.1149... Val Loss: 2.0899\n",
            "Epoch: 7/25... Step: 230... Loss: 2.1055... Val Loss: 2.0691\n",
            "Epoch: 7/25... Step: 240... Loss: 2.0572... Val Loss: 2.0652\n",
            "Epoch: 7/25... Step: 250... Loss: 2.0470... Val Loss: 2.0373\n",
            "Epoch: 7/25... Step: 260... Loss: 2.0624... Val Loss: 2.0236\n",
            "Epoch: 8/25... Step: 270... Loss: 2.0506... Val Loss: 2.0182\n",
            "Epoch: 8/25... Step: 280... Loss: 2.0132... Val Loss: 2.0063\n",
            "Epoch: 8/25... Step: 290... Loss: 2.0065... Val Loss: 1.9895\n",
            "Epoch: 8/25... Step: 300... Loss: 1.9901... Val Loss: 1.9708\n",
            "Epoch: 9/25... Step: 310... Loss: 1.9897... Val Loss: 1.9677\n",
            "Epoch: 9/25... Step: 320... Loss: 1.9708... Val Loss: 1.9595\n",
            "Epoch: 9/25... Step: 330... Loss: 1.9503... Val Loss: 1.9398\n",
            "Epoch: 9/25... Step: 340... Loss: 1.9732... Val Loss: 1.9277\n",
            "Epoch: 10/25... Step: 350... Loss: 1.9887... Val Loss: 1.9221\n",
            "Epoch: 10/25... Step: 360... Loss: 1.9077... Val Loss: 1.9023\n",
            "Epoch: 10/25... Step: 370... Loss: 1.9152... Val Loss: 1.8944\n",
            "Epoch: 10/25... Step: 380... Loss: 1.9162... Val Loss: 1.8890\n",
            "Epoch: 11/25... Step: 390... Loss: 1.8721... Val Loss: 1.8908\n",
            "Epoch: 11/25... Step: 400... Loss: 1.8684... Val Loss: 1.8681\n",
            "Epoch: 11/25... Step: 410... Loss: 1.8766... Val Loss: 1.8625\n",
            "Epoch: 12/25... Step: 420... Loss: 1.8669... Val Loss: 1.8606\n",
            "Epoch: 12/25... Step: 430... Loss: 1.8306... Val Loss: 1.8442\n",
            "Epoch: 12/25... Step: 440... Loss: 1.8310... Val Loss: 1.8326\n",
            "Epoch: 12/25... Step: 450... Loss: 1.8584... Val Loss: 1.8282\n",
            "Epoch: 13/25... Step: 460... Loss: 1.8454... Val Loss: 1.8247\n",
            "Epoch: 13/25... Step: 470... Loss: 1.8203... Val Loss: 1.8082\n",
            "Epoch: 13/25... Step: 480... Loss: 1.8195... Val Loss: 1.8016\n",
            "Epoch: 13/25... Step: 490... Loss: 1.8087... Val Loss: 1.8012\n",
            "Epoch: 14/25... Step: 500... Loss: 1.8134... Val Loss: 1.7917\n",
            "Epoch: 14/25... Step: 510... Loss: 1.7956... Val Loss: 1.7826\n",
            "Epoch: 14/25... Step: 520... Loss: 1.7874... Val Loss: 1.7797\n",
            "Epoch: 14/25... Step: 530... Loss: 1.8033... Val Loss: 1.7751\n",
            "Epoch: 15/25... Step: 540... Loss: 1.8086... Val Loss: 1.7663\n",
            "Epoch: 15/25... Step: 550... Loss: 1.7368... Val Loss: 1.7539\n",
            "Epoch: 15/25... Step: 560... Loss: 1.7603... Val Loss: 1.7487\n",
            "Epoch: 15/25... Step: 570... Loss: 1.7781... Val Loss: 1.7434\n",
            "Epoch: 16/25... Step: 580... Loss: 1.7271... Val Loss: 1.7464\n",
            "Epoch: 16/25... Step: 590... Loss: 1.7385... Val Loss: 1.7312\n",
            "Epoch: 16/25... Step: 600... Loss: 1.7330... Val Loss: 1.7311\n",
            "Epoch: 17/25... Step: 610... Loss: 1.7403... Val Loss: 1.7263\n",
            "Epoch: 17/25... Step: 620... Loss: 1.7085... Val Loss: 1.7253\n",
            "Epoch: 17/25... Step: 630... Loss: 1.7133... Val Loss: 1.7121\n",
            "Epoch: 17/25... Step: 640... Loss: 1.7359... Val Loss: 1.7127\n",
            "Epoch: 18/25... Step: 650... Loss: 1.7218... Val Loss: 1.7026\n",
            "Epoch: 18/25... Step: 660... Loss: 1.6866... Val Loss: 1.6951\n",
            "Epoch: 18/25... Step: 670... Loss: 1.6983... Val Loss: 1.6943\n",
            "Epoch: 18/25... Step: 680... Loss: 1.6843... Val Loss: 1.6897\n",
            "Epoch: 19/25... Step: 690... Loss: 1.6869... Val Loss: 1.6866\n",
            "Epoch: 19/25... Step: 700... Loss: 1.6827... Val Loss: 1.6836\n",
            "Epoch: 19/25... Step: 710... Loss: 1.6820... Val Loss: 1.6791\n",
            "Epoch: 19/25... Step: 720... Loss: 1.6788... Val Loss: 1.6679\n",
            "Epoch: 20/25... Step: 730... Loss: 1.6945... Val Loss: 1.6665\n",
            "Epoch: 20/25... Step: 740... Loss: 1.6420... Val Loss: 1.6604\n",
            "Epoch: 20/25... Step: 750... Loss: 1.6494... Val Loss: 1.6648\n",
            "Epoch: 20/25... Step: 760... Loss: 1.6613... Val Loss: 1.6649\n",
            "Epoch: 21/25... Step: 770... Loss: 1.6230... Val Loss: 1.6529\n",
            "Epoch: 21/25... Step: 780... Loss: 1.6293... Val Loss: 1.6483\n",
            "Epoch: 21/25... Step: 790... Loss: 1.6328... Val Loss: 1.6431\n",
            "Epoch: 22/25... Step: 800... Loss: 1.6457... Val Loss: 1.6440\n",
            "Epoch: 22/25... Step: 810... Loss: 1.6111... Val Loss: 1.6429\n",
            "Epoch: 22/25... Step: 820... Loss: 1.6206... Val Loss: 1.6333\n",
            "Epoch: 22/25... Step: 830... Loss: 1.6351... Val Loss: 1.6424\n",
            "Epoch: 23/25... Step: 840... Loss: 1.6277... Val Loss: 1.6335\n",
            "Epoch: 23/25... Step: 850... Loss: 1.5956... Val Loss: 1.6258\n",
            "Epoch: 23/25... Step: 860... Loss: 1.6066... Val Loss: 1.6244\n",
            "Epoch: 23/25... Step: 870... Loss: 1.6035... Val Loss: 1.6347\n",
            "Epoch: 24/25... Step: 880... Loss: 1.5884... Val Loss: 1.6249\n",
            "Epoch: 24/25... Step: 890... Loss: 1.5936... Val Loss: 1.6202\n",
            "Epoch: 24/25... Step: 900... Loss: 1.5953... Val Loss: 1.6182\n",
            "Epoch: 24/25... Step: 910... Loss: 1.6021... Val Loss: 1.6133\n",
            "Epoch: 25/25... Step: 920... Loss: 1.6001... Val Loss: 1.6038\n",
            "Epoch: 25/25... Step: 930... Loss: 1.5640... Val Loss: 1.6092\n",
            "Epoch: 25/25... Step: 940... Loss: 1.5754... Val Loss: 1.6003\n",
            "Epoch: 25/25... Step: 950... Loss: 1.5857... Val Loss: 1.6026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hGn0SbXTQfX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(net, size, prime='The', top_k=None):\n",
        "\n",
        "    net.eval()\n",
        "    \n",
        "    # First off, run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = net.predict(ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Now pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = net.predict(chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPv0fYATQfTG",
        "colab_type": "code",
        "outputId": "3c8d6200-c105-48bd-dbd7-60372800722f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1029
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='To be or not to be', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "To be or not to bell,\n",
            "And made hus a polere of my hand.\n",
            "\n",
            "CORIOLANUS:\n",
            "I have be a there is shome to me,\n",
            "Well sheep had stain and shanger of a morth.\n",
            "\n",
            "SICINIUS:\n",
            "The such one state a childry, wherefore.\n",
            "\n",
            "MENENIUS:\n",
            "O worthy hands,\n",
            "The stroves of the son, time out to my stears on a man armon and wifold to hear hus that a stranges, who, the whare as he to me to he to me that tell thee,\n",
            "To see this bands of theing of a shripts and whom his sonsering with a store as was a solfor our thee?\n",
            "\n",
            "Second Servingman:\n",
            "Which he shallst an hally the strieges of subres of the cause, and thy barther of the chombers, breath my brow to tell thee to me, and this dause this his some himself so men,\n",
            "The secomair that a wenter's sides are as him as\n",
            "this and to see it hat.\n",
            "\n",
            "BRUTUS:\n",
            "With the so farst wise high this freens,\n",
            "But that with hapet heart the tales and have\n",
            "The sone of make this sour are, this the man much anse\n",
            "And which the partinious shall of a goneren sents,\n",
            "Which the word wind they shall a place they dised\n",
            "Is the didesters to make thy bast tongee\n",
            "To see a souse, that I have stay and farther, thy lord,\n",
            "Thou doth must courtest to he tas to be a man, and soul suck speach.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Marry, my great strule, than a that of some at seting this true hard of the plint someting\n",
            "That thou wast now shall the compreased to me.\n",
            "To him of make of soul, we want to bear\n",
            "Which to being tood a chorded thought an hants\n",
            "And we discrack thee so the cried it seen,\n",
            "And most thou should breat on and my steat of the cords.\n",
            "\n",
            "KING RICHARD III:\n",
            "Thy word,\n",
            "Which thou day stand, stought they, sirst him them\n",
            "As thin stend and still a stallow hearts\n",
            "Our deviled on my love wort towe a man of thousand son that the were thou and the mean with a mate of a morrow.\n",
            "\n",
            "KING RICHARD II:\n",
            "Hade were is never be this thouser to the terme,\n",
            "To the creater and the cause and fline\n",
            "In sout to seed my states to be are true.\n",
            "\n",
            "BRUTUS:\n",
            "When, I what he,\n",
            "What how and the poist a mendy,\n",
            "And to her stint to take to that the mores, side they hath this sunce \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_70GCQ5B1L2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jxh19CRi7IEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NietzscheRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "330e578c-9f0c-45a6-e374-38b3123162f5",
        "id": "OYmqpEr57Nr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/nietzsche.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "PREFACE\n",
            "\n",
            "\n",
            "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
            "for suspecting that all philosophers, in so far as they have been\n",
            "dogmatists, have failed to understand women--that the terrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "cc6bd3ff-b59b-4952-d92b-286eda4a956b",
        "id": "X5JhTSfA7NsP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:200893]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {'D', 'p', 'm', 'R', 'v', 'I', ';', '8', 'l', 'e', '_', '=', 'a', 'F', 'd', '7', 'Æ', 'j', 'X', '[', ')', 'G', 'B', '1', 'æ', 'g', 'Z', ' ', '5', 'S', 'U', 'c', 'V', 'x', '0', 'ë', 's', 'Y', ',', '?', 'k', '-', 'é', 'O', 'q', 'P', 'T', 'N', 'ä', 'o', '.', 'h', '\\n', 'z', \"'\", '3', 'K', 'H', '!', '9', 'C', 'u', 'J', 'n', 'E', 'f', '4', ']', 'A', 'w', 'r', 'W', 't', 'Q', 'L', ':', 'i', 'b', '(', 'M', '2', '6', '\"', 'y'}\n",
            "Length of Unique characters: 84\n",
            "Number of characters in data: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e01258a7-9c44-459c-82f3-a2303e65b976",
        "id": "7uYW9sbF7Nsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{'D': 0, 'p': 1, 'm': 2, 'R': 3, 'v': 4, 'I': 5, ';': 6, '8': 7, 'l': 8, 'e': 9, '_': 10, '=': 11, 'a': 12, 'F': 13, 'd': 14, '7': 15, 'Æ': 16, 'j': 17, 'X': 18, '[': 19, ')': 20, 'G': 21, 'B': 22, '1': 23, 'æ': 24, 'g': 25, 'Z': 26, ' ': 27, '5': 28, 'S': 29, 'U': 30, 'c': 31, 'V': 32, 'x': 33, '0': 34, 'ë': 35, 's': 36, 'Y': 37, ',': 38, '?': 39, 'k': 40, '-': 41, 'é': 42, 'O': 43, 'q': 44, 'P': 45, 'T': 46, 'N': 47, 'ä': 48, 'o': 49, '.': 50, 'h': 51, '\\n': 52, 'z': 53, \"'\": 54, '3': 55, 'K': 56, 'H': 57, '!': 58, '9': 59, 'C': 60, 'u': 61, 'J': 62, 'n': 63, 'E': 64, 'f': 65, '4': 66, ']': 67, 'A': 68, 'w': 69, 'r': 70, 'W': 71, 't': 72, 'Q': 73, 'L': 74, ':': 75, 'i': 76, 'b': 77, '(': 78, 'M': 79, '2': 80, '6': 81, '\"': 82, 'y': 83}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fLz1RKZp7Nss",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "fcf67ad4-ba13-4e41-f92d-de9355953e74",
        "id": "bn4JJ2Ek7Nsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[45, 3, 64, 13, 68, 60, 64, 52, 52, 52, 29, 30, 45, 45, 43, 29, 5, 47, 21, 27, 72, 51, 12, 72, 27, 46, 70, 61, 72, 51, 27, 76, 36, 27, 12, 27, 69, 49, 2, 12, 63, 41, 41, 69, 51, 12, 72, 27, 72, 51, 9, 63, 39, 27, 5, 36, 27, 72, 51, 9, 70, 9, 27, 63, 49, 72, 27, 25, 70, 49, 61, 63, 14, 52, 65, 49, 70, 27, 36, 61, 36, 1, 9, 31, 72, 76, 63, 25, 27, 72, 51, 12, 72, 27, 12, 8, 8, 27, 1, 51] 100 2008\n",
            "[3, 64, 13, 68, 60, 64, 52, 52, 52, 29, 30, 45, 45, 43, 29, 5, 47, 21, 27, 72, 51, 12, 72, 27, 46, 70, 61, 72, 51, 27, 76, 36, 27, 12, 27, 69, 49, 2, 12, 63, 41, 41, 69, 51, 12, 72, 27, 72, 51, 9, 63, 39, 27, 5, 36, 27, 72, 51, 9, 70, 9, 27, 63, 49, 72, 27, 25, 70, 49, 61, 63, 14, 52, 65, 49, 70, 27, 36, 61, 36, 1, 9, 31, 72, 76, 63, 25, 27, 72, 51, 12, 72, 27, 12, 8, 8, 27, 1, 51, 76] 100 2008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0c23e809-9570-4751-b91d-9d824a5783e1",
        "id": "4VSnKbx_7NtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: PREFACE\n",
            "\n",
            "\n",
            "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
            "for suspecting that all ph\n",
            "Output: REFACE\n",
            "\n",
            "\n",
            "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
            "for suspecting that all phi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "js8rlyr67Ntj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8d9950e5-b3cf-4d5b-9f01-d44137b09e77",
        "id": "ODD3F2Ky7Nt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (2008, 100, 84)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7f0fd962-2a3c-4746-d9fd-383fc76405bd",
        "id": "24tr120h7NuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3 64 13 68 60 64 52 52 52 29 30 45 45 43 29  5 47 21 27 72 51 12 72 27\n",
            " 46 70 61 72 51 27 76 36 27 12 27 69 49  2 12 63 41 41 69 51 12 72 27 72\n",
            " 51  9 63 39 27  5 36 27 72 51  9 70  9 27 63 49 72 27 25 70 49 61 63 14\n",
            " 52 65 49 70 27 36 61 36  1  9 31 72 76 63 25 27 72 51 12 72 27 12  8  8\n",
            " 27  1 51 76] (2008, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "80a6e6b7-2d7d-4a23-bf4d-aa71e95b6571",
        "id": "p8r3PRLD7NuX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (1606, 100, 84) (1606, 100)\n",
            "Validation: (402, 100, 84) (402, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UCEJNaKr7QjM",
        "colab_type": "code",
        "outputId": "abe2e74f-582e-466c-ee40-a5d965924673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(84, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=84, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "tmUyEMyfnjlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8phhTbJ7nKt",
        "colab_type": "code",
        "outputId": "e551654a-38eb-473f-c323-168ef0a53c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.3786... Val Loss: 3.3212\n",
            "Epoch: 2/25... Step: 20... Loss: 3.2585... Val Loss: 3.2214\n",
            "Epoch: 3/25... Step: 30... Loss: 3.1298... Val Loss: 3.0956\n",
            "Epoch: 4/25... Step: 40... Loss: 2.9663... Val Loss: 2.9281\n",
            "Epoch: 5/25... Step: 50... Loss: 2.7799... Val Loss: 2.7638\n",
            "Epoch: 5/25... Step: 60... Loss: 2.6517... Val Loss: 2.6701\n",
            "Epoch: 6/25... Step: 70... Loss: 2.6086... Val Loss: 2.6001\n",
            "Epoch: 7/25... Step: 80... Loss: 2.5806... Val Loss: 2.5509\n",
            "Epoch: 8/25... Step: 90... Loss: 2.5206... Val Loss: 2.5102\n",
            "Epoch: 9/25... Step: 100... Loss: 2.4815... Val Loss: 2.4703\n",
            "Epoch: 10/25... Step: 110... Loss: 2.4498... Val Loss: 2.4448\n",
            "Epoch: 10/25... Step: 120... Loss: 2.3832... Val Loss: 2.4092\n",
            "Epoch: 11/25... Step: 130... Loss: 2.3723... Val Loss: 2.3779\n",
            "Epoch: 12/25... Step: 140... Loss: 2.3804... Val Loss: 2.3525\n",
            "Epoch: 13/25... Step: 150... Loss: 2.3165... Val Loss: 2.3275\n",
            "Epoch: 14/25... Step: 160... Loss: 2.3002... Val Loss: 2.2984\n",
            "Epoch: 15/25... Step: 170... Loss: 2.2768... Val Loss: 2.2780\n",
            "Epoch: 15/25... Step: 180... Loss: 2.2150... Val Loss: 2.2512\n",
            "Epoch: 16/25... Step: 190... Loss: 2.2089... Val Loss: 2.2300\n",
            "Epoch: 17/25... Step: 200... Loss: 2.2170... Val Loss: 2.2086\n",
            "Epoch: 18/25... Step: 210... Loss: 2.1807... Val Loss: 2.1886\n",
            "Epoch: 19/25... Step: 220... Loss: 2.1637... Val Loss: 2.1651\n",
            "Epoch: 20/25... Step: 230... Loss: 2.1410... Val Loss: 2.1514\n",
            "Epoch: 20/25... Step: 240... Loss: 2.0826... Val Loss: 2.1320\n",
            "Epoch: 21/25... Step: 250... Loss: 2.0940... Val Loss: 2.1126\n",
            "Epoch: 22/25... Step: 260... Loss: 2.0882... Val Loss: 2.0992\n",
            "Epoch: 23/25... Step: 270... Loss: 2.0577... Val Loss: 2.0854\n",
            "Epoch: 24/25... Step: 280... Loss: 2.0424... Val Loss: 2.0768\n",
            "Epoch: 25/25... Step: 290... Loss: 2.0146... Val Loss: 2.0557\n",
            "Epoch: 25/25... Step: 300... Loss: 1.9671... Val Loss: 2.0389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FDvWGdwY7wnB",
        "colab_type": "code",
        "outputId": "c309acc9-54b8-41ea-bf42-678a9201819c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='Every great philosophy', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Every great philosophy.\n",
            "\n",
            "65. Wo lowe as all sere that the prost of the his oncation. Ane the\n",
            "plessition of thisk of the perition of serecasing that at the porest of the calute a perisis to the sachite of this sears fart alo all trisg of a thish on is ancerting, and and\n",
            "touth of--in this surablicising tion and\n",
            "that in the concauly\n",
            "of to sente them trigh to be a dentired of their have in the riscess, itself the sained and\n",
            "mosters and as ont ofle the mort of the moderation of shaig ance tain this sears fict of that\n",
            "ther in is alles and efont and\n",
            "much is the resting or one\n",
            "to\n",
            "their incaine, and insucalie at of the sarn and thus a manting this sain for and inserites,\n",
            "whe inselies itself, indorstanced. To all the conciest of\n",
            "muralined which is incintly te ant intoring to and ast that the\n",
            "pertert of such as astominated to be tree the sare imself camself in onlereds of cersingicare one ore penseste and surition ancestand\n",
            "tomestite of a surition the man to that he priles in the rost as muntersto the miditing inderis and such of\n",
            "the croutidic als\n",
            "altound incerality it incertinct and the contions and to a the cand in the\n",
            "sermictly itself in when\n",
            "suppech the sain themety of to the reciare of that the comstarnce suct, and, at the montire, which inserest in the\n",
            "carie to if it is it, and expiritains\n",
            "and andincies, and atsing to as the couse that atered starious astemperstend and all the certe of\n",
            "and to a caution to beem the pose oppirated to the superion a caulter the\n",
            "poritation it to be a montes of the canter ont oncesenting and senigents to serfict to in which to be our is tratust of secianicy,\n",
            "which the conses, as thought all astome himserfity of their that in a conce them as\n",
            "a migher als the perposs itself, and\n",
            "the consices of alsomantes,\" and ancouther\n",
            "ther alsomen thay hay arouthing the complated--of that istent and must bat in thur in itself canster of meat ansomething tand to its of the regrationss, its to maty of heasty, and\n",
            "ceness of this its sore a mart and aster it is not tore the sectulious\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KS6WkiPV75gt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5CYElCvL79EH"
      },
      "cell_type": "markdown",
      "source": [
        "## AustenRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6c895c5d-d2c5-4fa3-905e-767741a3106e",
        "id": "TaO7roTI79ET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/31100.txt'\n",
        "import io\n",
        "\n",
        "with io.open(file_path, 'r', encoding='windows-1252') as f:\n",
        "  \n",
        "    data = f.read().lower()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "\n",
            "project gutenberg's the complete works of jane austen, by jane austen\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  you may copy it, give it aw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "03009698-3f5e-4606-8fb5-5cdc0bf0d78f",
        "id": "GpWK2u7r79Ev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:473597]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {',', 'g', ']', '.', '(', '5', '1', '?', 's', 'v', 'j', 'o', '/', 'i', 'k', '\\n', '%', '&', 'm', '[', 'l', '4', 'r', ' ', 'y', '\\xa0', ';', 'q', 'u', '-', 'f', ':', '6', '9', 'b', '0', 'a', 'h', ')', 'p', '!', 'c', '#', '_', '$', \"'\", 'd', '8', '*', '2', '\"', 'n', '3', 'e', 't', '7', 'x', 'z', '@', 'w'}\n",
            "Length of Unique characters: 60\n",
            "Number of characters in data: 4373597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "47602306-10ce-420a-cfd5-16826880f644",
        "id": "ohsO2uuZ79E-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{',': 0, 'g': 1, ']': 2, '.': 3, '(': 4, '5': 5, '1': 6, '?': 7, 's': 8, 'v': 9, 'j': 10, 'o': 11, '/': 12, 'i': 13, 'k': 14, '\\n': 15, '%': 16, '&': 17, 'm': 18, '[': 19, 'l': 20, '4': 21, 'r': 22, ' ': 23, 'y': 24, '\\xa0': 25, ';': 26, 'q': 27, 'u': 28, '-': 29, 'f': 30, ':': 31, '6': 32, '9': 33, 'b': 34, '0': 35, 'a': 36, 'h': 37, ')': 38, 'p': 39, '!': 40, 'c': 41, '#': 42, '_': 43, '$': 44, \"'\": 45, 'd': 46, '8': 47, '*': 48, '2': 49, '\"': 50, 'n': 51, '3': 52, 'e': 53, 't': 54, '7': 55, 'x': 56, 'z': 57, '@': 58, 'w': 59}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MpgnNxoQ79FT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d725c0dd-74e3-4729-c01c-cfbc7f4edf6b",
        "id": "XVwF-Gpj79Fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15, 39, 22, 11, 10, 53, 41, 54, 23, 1, 28, 54, 53, 51, 34, 53, 22, 1, 45, 8, 23, 54, 37, 53, 23, 41, 11, 18, 39, 20, 53, 54, 53, 23, 59, 11, 22, 14, 8, 23, 11, 30, 23, 10, 36, 51, 53, 23, 36, 28, 8, 54, 53, 51, 0, 23, 34, 24, 23, 10, 36, 51, 53, 23, 36, 28, 8, 54, 53, 51, 15, 15, 54, 37, 13, 8, 23, 53, 34, 11, 11, 14, 23, 13, 8, 23, 30, 11, 22, 23, 54, 37, 53, 23, 28, 8, 53, 23, 11, 30] 100 4735\n",
            "[39, 22, 11, 10, 53, 41, 54, 23, 1, 28, 54, 53, 51, 34, 53, 22, 1, 45, 8, 23, 54, 37, 53, 23, 41, 11, 18, 39, 20, 53, 54, 53, 23, 59, 11, 22, 14, 8, 23, 11, 30, 23, 10, 36, 51, 53, 23, 36, 28, 8, 54, 53, 51, 0, 23, 34, 24, 23, 10, 36, 51, 53, 23, 36, 28, 8, 54, 53, 51, 15, 15, 54, 37, 13, 8, 23, 53, 34, 11, 11, 14, 23, 13, 8, 23, 30, 11, 22, 23, 54, 37, 53, 23, 28, 8, 53, 23, 11, 30, 23] 100 4735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5e914736-1665-4e65-ec79-d1d79056db62",
        "id": "rW2cBY2479Ft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            "project gutenberg's the complete works of jane austen, by jane austen\n",
            "\n",
            "this ebook is for the use of\n",
            "Output: project gutenberg's the complete works of jane austen, by jane austen\n",
            "\n",
            "this ebook is for the use of \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yUgFGhWG79GA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "bd29489e-08a9-40f1-acfa-5753dd8db285",
        "id": "udA6Q4QC79GO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (4735, 100, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "15e358b0-6ad4-41d9-bf8d-2c51e60865e0",
        "id": "3YWOOcgl79Gm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[39 22 11 10 53 41 54 23  1 28 54 53 51 34 53 22  1 45  8 23 54 37 53 23\n",
            " 41 11 18 39 20 53 54 53 23 59 11 22 14  8 23 11 30 23 10 36 51 53 23 36\n",
            " 28  8 54 53 51  0 23 34 24 23 10 36 51 53 23 36 28  8 54 53 51 15 15 54\n",
            " 37 13  8 23 53 34 11 11 14 23 13  8 23 30 11 22 23 54 37 53 23 28  8 53\n",
            " 23 11 30 23] (4735, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "509a1580-2440-4d23-d427-a45f04fb2714",
        "id": "CXQHPkMT79G1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (3788, 100, 60) (3788, 100)\n",
            "Validation: (947, 100, 60) (947, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zbbl7Gpx79HP",
        "outputId": "6720b7e0-839f-49d0-b6dc-c13363f056f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(60, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=60, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "2OV3t5E9Sard",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vu8MX_Sh79Hc",
        "outputId": "56cd0f5a-b35d-486f-bcc2-11235ade28d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.1571... Val Loss: 3.1588\n",
            "Epoch: 1/25... Step: 20... Loss: 3.0604... Val Loss: 3.0484\n",
            "Epoch: 2/25... Step: 30... Loss: 2.9630... Val Loss: 2.9389\n",
            "Epoch: 2/25... Step: 40... Loss: 2.8130... Val Loss: 2.7876\n",
            "Epoch: 2/25... Step: 50... Loss: 2.6253... Val Loss: 2.6408\n",
            "Epoch: 3/25... Step: 60... Loss: 2.5456... Val Loss: 2.5417\n",
            "Epoch: 3/25... Step: 70... Loss: 2.4814... Val Loss: 2.4742\n",
            "Epoch: 3/25... Step: 80... Loss: 2.4178... Val Loss: 2.4235\n",
            "Epoch: 4/25... Step: 90... Loss: 2.3910... Val Loss: 2.3837\n",
            "Epoch: 4/25... Step: 100... Loss: 2.3445... Val Loss: 2.3465\n",
            "Epoch: 4/25... Step: 110... Loss: 2.3141... Val Loss: 2.3123\n",
            "Epoch: 5/25... Step: 120... Loss: 2.2844... Val Loss: 2.2816\n",
            "Epoch: 5/25... Step: 130... Loss: 2.2444... Val Loss: 2.2545\n",
            "Epoch: 5/25... Step: 140... Loss: 2.2485... Val Loss: 2.2241\n",
            "Epoch: 6/25... Step: 150... Loss: 2.1817... Val Loss: 2.1955\n",
            "Epoch: 6/25... Step: 160... Loss: 2.1732... Val Loss: 2.1694\n",
            "Epoch: 6/25... Step: 170... Loss: 2.1509... Val Loss: 2.1440\n",
            "Epoch: 7/25... Step: 180... Loss: 2.1080... Val Loss: 2.1186\n",
            "Epoch: 7/25... Step: 190... Loss: 2.1066... Val Loss: 2.1000\n",
            "Epoch: 7/25... Step: 200... Loss: 2.0747... Val Loss: 2.0693\n",
            "Epoch: 8/25... Step: 210... Loss: 2.0173... Val Loss: 2.0549\n",
            "Epoch: 8/25... Step: 220... Loss: 2.0120... Val Loss: 2.0271\n",
            "Epoch: 8/25... Step: 230... Loss: 2.0178... Val Loss: 2.0101\n",
            "Epoch: 9/25... Step: 240... Loss: 1.9777... Val Loss: 1.9854\n",
            "Epoch: 9/25... Step: 250... Loss: 1.9687... Val Loss: 1.9719\n",
            "Epoch: 9/25... Step: 260... Loss: 1.9321... Val Loss: 1.9525\n",
            "Epoch: 10/25... Step: 270... Loss: 1.9248... Val Loss: 1.9331\n",
            "Epoch: 10/25... Step: 280... Loss: 1.9184... Val Loss: 1.9144\n",
            "Epoch: 10/25... Step: 290... Loss: 1.9381... Val Loss: 1.9010\n",
            "Epoch: 11/25... Step: 300... Loss: 1.8651... Val Loss: 1.8820\n",
            "Epoch: 11/25... Step: 310... Loss: 1.8455... Val Loss: 1.8673\n",
            "Epoch: 12/25... Step: 320... Loss: 1.8271... Val Loss: 1.8551\n",
            "Epoch: 12/25... Step: 330... Loss: 1.8035... Val Loss: 1.8355\n",
            "Epoch: 12/25... Step: 340... Loss: 1.7677... Val Loss: 1.8246\n",
            "Epoch: 13/25... Step: 350... Loss: 1.7634... Val Loss: 1.8133\n",
            "Epoch: 13/25... Step: 360... Loss: 1.7770... Val Loss: 1.7955\n",
            "Epoch: 13/25... Step: 370... Loss: 1.7529... Val Loss: 1.7938\n",
            "Epoch: 14/25... Step: 380... Loss: 1.7863... Val Loss: 1.7727\n",
            "Epoch: 14/25... Step: 390... Loss: 1.7354... Val Loss: 1.7601\n",
            "Epoch: 14/25... Step: 400... Loss: 1.7356... Val Loss: 1.7469\n",
            "Epoch: 15/25... Step: 410... Loss: 1.7221... Val Loss: 1.7358\n",
            "Epoch: 15/25... Step: 420... Loss: 1.6813... Val Loss: 1.7301\n",
            "Epoch: 15/25... Step: 430... Loss: 1.7267... Val Loss: 1.7210\n",
            "Epoch: 16/25... Step: 440... Loss: 1.6910... Val Loss: 1.7068\n",
            "Epoch: 16/25... Step: 450... Loss: 1.7040... Val Loss: 1.6968\n",
            "Epoch: 16/25... Step: 460... Loss: 1.6538... Val Loss: 1.6915\n",
            "Epoch: 17/25... Step: 470... Loss: 1.6479... Val Loss: 1.6780\n",
            "Epoch: 17/25... Step: 480... Loss: 1.6655... Val Loss: 1.6686\n",
            "Epoch: 17/25... Step: 490... Loss: 1.6494... Val Loss: 1.6686\n",
            "Epoch: 18/25... Step: 500... Loss: 1.6026... Val Loss: 1.6543\n",
            "Epoch: 18/25... Step: 510... Loss: 1.6033... Val Loss: 1.6487\n",
            "Epoch: 18/25... Step: 520... Loss: 1.6053... Val Loss: 1.6448\n",
            "Epoch: 19/25... Step: 530... Loss: 1.5747... Val Loss: 1.6339\n",
            "Epoch: 19/25... Step: 540... Loss: 1.5822... Val Loss: 1.6315\n",
            "Epoch: 19/25... Step: 550... Loss: 1.5535... Val Loss: 1.6256\n",
            "Epoch: 20/25... Step: 560... Loss: 1.5759... Val Loss: 1.6123\n",
            "Epoch: 20/25... Step: 570... Loss: 1.5647... Val Loss: 1.6083\n",
            "Epoch: 20/25... Step: 580... Loss: 1.6062... Val Loss: 1.6044\n",
            "Epoch: 21/25... Step: 590... Loss: 1.5380... Val Loss: 1.5945\n",
            "Epoch: 21/25... Step: 600... Loss: 1.5332... Val Loss: 1.5940\n",
            "Epoch: 22/25... Step: 610... Loss: 1.4992... Val Loss: 1.5886\n",
            "Epoch: 22/25... Step: 620... Loss: 1.5064... Val Loss: 1.5785\n",
            "Epoch: 22/25... Step: 630... Loss: 1.4793... Val Loss: 1.5836\n",
            "Epoch: 23/25... Step: 640... Loss: 1.4909... Val Loss: 1.5736\n",
            "Epoch: 23/25... Step: 650... Loss: 1.5111... Val Loss: 1.5632\n",
            "Epoch: 23/25... Step: 660... Loss: 1.4868... Val Loss: 1.5688\n",
            "Epoch: 24/25... Step: 670... Loss: 1.5149... Val Loss: 1.5595\n",
            "Epoch: 24/25... Step: 680... Loss: 1.4802... Val Loss: 1.5585\n",
            "Epoch: 24/25... Step: 690... Loss: 1.4937... Val Loss: 1.5625\n",
            "Epoch: 25/25... Step: 700... Loss: 1.4787... Val Loss: 1.5496\n",
            "Epoch: 25/25... Step: 710... Loss: 1.4404... Val Loss: 1.5469\n",
            "Epoch: 25/25... Step: 720... Loss: 1.4866... Val Loss: 1.5437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sos-vFm279Hh",
        "outputId": "08ee3add-2daa-47fa-b575-a5aa43f5fc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='vanity was the beginning', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "vanity was the beginning on one to the father was not believed the mort any our preter to\n",
            "being and an any of me always\n",
            "and mrs smother, i she chared as to the farly to stay\n",
            "sersperd and mind existen if an\n",
            "a concert was to the parracely of the mind, and at\n",
            "lyst had been astention with the poor a seeing to be\n",
            "an to book of the part convensed,\n",
            "and the seemed to be and the stall, the country, and they were such the friends, or the\n",
            "conferst the cried to have seen one other say.\"\n",
            "\n",
            "\"nessed you make something to some a concisions, to be care, i with more them.\n",
            "\n",
            "anne was too to sen this\n",
            "at the same sense.\n",
            "\n",
            "i am sure you, said he seet to be concerned to her, to be the manner of having a gettlemen, was to the pase of she seemed his friends he\n",
            "had been as\n",
            "she had been to home than of at his foot, who had a gid not the forture all his acquaintance.  anne some to\n",
            "decend the rest tearns to have house indeed, it was not and all mr elliot and the parting one of him.\n",
            "\n",
            "she had\n",
            "samed her side, and was not that he mad to be a great morrong, and all the possibibitity of them, in at least on the elliot, that he could not be a siderit with of the well on\n",
            "his was to be soon.  it was to see of, he\n",
            "can south.  this had neer as an accommonded, the concistant head her always being anne to be came of them, the family for she sent it a good on the card.  they could not think that as the port she could say a most\n",
            "marray, there has been a sole\n",
            "soon on the sirteres, and who house that their walked any convince of anything any other to be at to be to to be\n",
            "it one the catherance of such he as as a gered to be, in their own captain harville's secing, wish\n",
            "shir or such anne.  thought which\n",
            "had been a companion that they was to see him before their confessed he\n",
            "most contented, which hereed ot letter and more to be that the something of sure sering the saye of an a stult of merit in the were word.  she had saided most hardly the first of the some too take themselves to the wonder as they crofled would be some tranely and marry a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VWXD1WgB79Hn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WbT3iqOy8A-S"
      },
      "cell_type": "markdown",
      "source": [
        "## DictionaryRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0b59b2b7-3c80-40e8-e640-fb80a415d910",
        "id": "Qxrp4qFN8A-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/pg29765.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read().lower()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "﻿the project gutenberg ebook of webster's unabridged dictionary, by various\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  you may copy it, give \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2898f4f7-b3ab-4edd-ad56-ec2f8f11a924",
        "id": "abhtjRv08A_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:156206]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {'&', 'a', '|', 'þ', 'h', 'w', '^', 'd', 'â', '1', 'ó', 'ã', 'ê', 'r', '@', '*', 'ë', 'y', '9', 'o', 'f', ' ', '/', 'ï', 'à', '½', 'å', '¼', 'k', \"'\", 'é', 'ì', 'ð', 'í', 'i', '3', 'ù', '2', 'ô', 'q', 'æ', '\\t', '%', '5', '7', '\"', '\\\\', '#', 'v', ',', '-', 'x', 'á', '=', '\\n', '\\ufeff', 'û', 'ñ', '°', ']', 'm', ':', '0', '¿', 'ö', '6', 'ú', 'e', 'u', '4', '[', 'g', 'b', 'ü', 'è', 's', ';', 't', '}', '{', '<', ')', 'ý', '~', 'î', '!', '(', '_', 'l', 'p', '$', 'ò', 'ç', '8', '÷', '>', '.', '¾', '£', 'º', '×', '`', 'z', '§', '+', 'c', 'n', 'j', 'ä'}\n",
            "Length of Unique characters: 109\n",
            "Number of characters in data: 27956206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ffeb54f6-a5a9-4ded-a00d-c65ee956d16c",
        "id": "SwzxYIjF8A_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{'&': 0, 'a': 1, '|': 2, 'þ': 3, 'h': 4, 'w': 5, '^': 6, 'd': 7, 'â': 8, '1': 9, 'ó': 10, 'ã': 11, 'ê': 12, 'r': 13, '@': 14, '*': 15, 'ë': 16, 'y': 17, '9': 18, 'o': 19, 'f': 20, ' ': 21, '/': 22, 'ï': 23, 'à': 24, '½': 25, 'å': 26, '¼': 27, 'k': 28, \"'\": 29, 'é': 30, 'ì': 31, 'ð': 32, 'í': 33, 'i': 34, '3': 35, 'ù': 36, '2': 37, 'ô': 38, 'q': 39, 'æ': 40, '\\t': 41, '%': 42, '5': 43, '7': 44, '\"': 45, '\\\\': 46, '#': 47, 'v': 48, ',': 49, '-': 50, 'x': 51, 'á': 52, '=': 53, '\\n': 54, '\\ufeff': 55, 'û': 56, 'ñ': 57, '°': 58, ']': 59, 'm': 60, ':': 61, '0': 62, '¿': 63, 'ö': 64, '6': 65, 'ú': 66, 'e': 67, 'u': 68, '4': 69, '[': 70, 'g': 71, 'b': 72, 'ü': 73, 'è': 74, 's': 75, ';': 76, 't': 77, '}': 78, '{': 79, '<': 80, ')': 81, 'ý': 82, '~': 83, 'î': 84, '!': 85, '(': 86, '_': 87, 'l': 88, 'p': 89, '$': 90, 'ò': 91, 'ç': 92, '8': 93, '÷': 94, '>': 95, '.': 96, '¾': 97, '£': 98, 'º': 99, '×': 100, '`': 101, 'z': 102, '§': 103, '+': 104, 'c': 105, 'n': 106, 'j': 107, 'ä': 108}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lVxKCRzo8A_p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1efad93f-2137-40be-dddc-6b41db985f97",
        "id": "6zFzIV-h8A_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[55, 77, 4, 67, 21, 89, 13, 19, 107, 67, 105, 77, 21, 71, 68, 77, 67, 106, 72, 67, 13, 71, 21, 67, 72, 19, 19, 28, 21, 19, 20, 21, 5, 67, 72, 75, 77, 67, 13, 29, 75, 21, 68, 106, 1, 72, 13, 34, 7, 71, 67, 7, 21, 7, 34, 105, 77, 34, 19, 106, 1, 13, 17, 49, 21, 72, 17, 21, 48, 1, 13, 34, 19, 68, 75, 54, 54, 77, 4, 34, 75, 21, 67, 72, 19, 19, 28, 21, 34, 75, 21, 20, 19, 13, 21, 77, 4, 67, 21, 68] 100 1562\n",
            "[77, 4, 67, 21, 89, 13, 19, 107, 67, 105, 77, 21, 71, 68, 77, 67, 106, 72, 67, 13, 71, 21, 67, 72, 19, 19, 28, 21, 19, 20, 21, 5, 67, 72, 75, 77, 67, 13, 29, 75, 21, 68, 106, 1, 72, 13, 34, 7, 71, 67, 7, 21, 7, 34, 105, 77, 34, 19, 106, 1, 13, 17, 49, 21, 72, 17, 21, 48, 1, 13, 34, 19, 68, 75, 54, 54, 77, 4, 34, 75, 21, 67, 72, 19, 19, 28, 21, 34, 75, 21, 20, 19, 13, 21, 77, 4, 67, 21, 68, 75] 100 1562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c459e5d2-222b-4d81-cb12-da7e41fbaee6",
        "id": "QYki7qd98BAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ﻿the project gutenberg ebook of webster's unabridged dictionary, by various\n",
            "\n",
            "this ebook is for the u\n",
            "Output: the project gutenberg ebook of webster's unabridged dictionary, by various\n",
            "\n",
            "this ebook is for the us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ld6TRLEQ8BAS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c2b44fb9-a947-4c0e-fe5f-e924d72dacce",
        "id": "11VRm8Q68BAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (1562, 100, 109)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "921e1dc2-382c-4fbe-fedb-286b4cf8a595",
        "id": "9mzNivCp8BAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 77   4  67  21  89  13  19 107  67 105  77  21  71  68  77  67 106  72\n",
            "  67  13  71  21  67  72  19  19  28  21  19  20  21   5  67  72  75  77\n",
            "  67  13  29  75  21  68 106   1  72  13  34   7  71  67   7  21   7  34\n",
            " 105  77  34  19 106   1  13  17  49  21  72  17  21  48   1  13  34  19\n",
            "  68  75  54  54  77   4  34  75  21  67  72  19  19  28  21  34  75  21\n",
            "  20  19  13  21  77   4  67  21  68  75] (1562, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "316c6a22-1168-463e-90fc-915dd93be869",
        "id": "bCcBGKPO8BBG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (1249, 100, 109) (1249, 100)\n",
            "Validation: (313, 100, 109) (313, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A082fTec8BBa",
        "outputId": "0b6e0104-5274-421a-e51c-6efdf1015eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(109, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=109, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "dtxmzPNlSUMU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUXtDaCS8BBl",
        "outputId": "1afd6a9c-16ec-4135-87e0-ebb2d5dbbd54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/25... Step: 10... Loss: 3.4775... Val Loss: 3.4398\n",
            "Epoch: 3/25... Step: 20... Loss: 3.3560... Val Loss: 3.3330\n",
            "Epoch: 4/25... Step: 30... Loss: 3.2230... Val Loss: 3.1962\n",
            "Epoch: 5/25... Step: 40... Loss: 3.0645... Val Loss: 3.0245\n",
            "Epoch: 6/25... Step: 50... Loss: 2.8395... Val Loss: 2.8186\n",
            "Epoch: 7/25... Step: 60... Loss: 2.7195... Val Loss: 2.6641\n",
            "Epoch: 8/25... Step: 70... Loss: 2.5964... Val Loss: 2.5909\n",
            "Epoch: 9/25... Step: 80... Loss: 2.5027... Val Loss: 2.5181\n",
            "Epoch: 10/25... Step: 90... Loss: 2.4404... Val Loss: 2.4613\n",
            "Epoch: 12/25... Step: 100... Loss: 2.4134... Val Loss: 2.4090\n",
            "Epoch: 13/25... Step: 110... Loss: 2.3840... Val Loss: 2.3708\n",
            "Epoch: 14/25... Step: 120... Loss: 2.3140... Val Loss: 2.3392\n",
            "Epoch: 15/25... Step: 130... Loss: 2.3620... Val Loss: 2.3083\n",
            "Epoch: 16/25... Step: 140... Loss: 2.3057... Val Loss: 2.2832\n",
            "Epoch: 17/25... Step: 150... Loss: 2.3228... Val Loss: 2.2521\n",
            "Epoch: 18/25... Step: 160... Loss: 2.2273... Val Loss: 2.2248\n",
            "Epoch: 19/25... Step: 170... Loss: 2.1994... Val Loss: 2.1956\n",
            "Epoch: 20/25... Step: 180... Loss: 2.1541... Val Loss: 2.1795\n",
            "Epoch: 22/25... Step: 190... Loss: 2.1398... Val Loss: 2.1679\n",
            "Epoch: 23/25... Step: 200... Loss: 2.1439... Val Loss: 2.1395\n",
            "Epoch: 24/25... Step: 210... Loss: 2.0617... Val Loss: 2.1227\n",
            "Epoch: 25/25... Step: 220... Loss: 2.1296... Val Loss: 2.1038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6SAApsFq8BBz",
        "outputId": "554a9823-8871-4c8e-9c3f-53bff070f35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1010
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='defn:', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "defn: the abrer is the the sher strenging in torerst of borde of the a that the trene comated tomes, the calded.\n",
            "\n",
            "abattice\n",
            "ab\"tho*ton, n.\n",
            "\n",
            "defn: son bothe a sea see palle sound; seanthere absint the price. [obs.] abast.]\n",
            "\n",
            "defn: the abord, as or abrite, to pricinatise abast.]\n",
            "\n",
            "1. the with as a abstion.\n",
            "\n",
            "absortation absicharin. ser abastit.]\n",
            "\n",
            "1. (lath.\n",
            "\n",
            "absole\n",
            "deand to promint of on absound the the abotive. abstrongus of an shall abrontered with of and, ind the actare a sol the ther to tous, and in sun to a astreming in tore the ande of thar ser an to bal thatinge to abester stat on the thits abs ofe marthes of siase. abathers of absort of bor to sting the corder or seed\n",
            "abated, abretintiting abord of ition abediss, an ingaling in tancity to beits or the tout, in abstion to seer the absting one with. [icp.]\n",
            "\n",
            "defn: to a derte sores of a to seed be absint or prosing sor absouss, n. a abred.\n",
            "\n",
            "abatias, abrace the aboter.\n",
            "\n",
            "abserace\n",
            "ab*se\"ti*able, a. etym: [l. abothivieness.\n",
            "\n",
            "defn: the abror withe a absored abotroun.\n",
            "\n",
            "absoustent\n",
            "ab\"a*tar\", n. etym: [pr. abaseden.]\n",
            "\n",
            "defn: to abrure for. ablor.]\n",
            "\n",
            "1. to abatten, an on is in aborig the press, a sen a parsentice a sund on abstion of abrorte.]\n",
            "\n",
            "1. to a bete to bat abored. aborter an abastion, ard ingerion is a abot in the sones of a soused the cher or achor than some the thas the sores in or prithous of ore accally abor or abrestiout in the sis ontite the tha paring ase the plesed abdust of abresisen.]\n",
            "\n",
            "abate\n",
            "ab\"te*nes, a. etym: [l. abrout tre absentise the acharines the the as ande parthous of absonge tion so to sedes of the partion, a superingent in ins in a anthact in a comerer a besene sea absol.] etym: [of. absentise.]\n",
            "\n",
            "1. an andat a preced a sorme then abstanct abstreste surtice to absert. etym: [l. abacerial at exprous.\n",
            "\n",
            "3. the\n",
            "an absoman of an offer the batith,\n",
            "ard inthe and wich inden abstrentithen ass intor the abred ably\n",
            "abstitite\n",
            "ab\"ing*ne, abverte, at absterse the abstr.\n",
            "\n",
            "abstrestion\n",
            "ab\"sor*tive, p. p. & pb. absender.]\n",
            "\n",
            "de\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rc7LIolO8BB9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QHsVttAG8EYI"
      },
      "cell_type": "markdown",
      "source": [
        "## ObamaRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "dd820974-a09e-4ff5-e651-8dce9d0f0b6c",
        "id": "W4q1dDnV8EYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/obama/input.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "To Chip, Kathy, and Nancy, who graciously shared your father with a nation that loved him; to Walter's friends, colleagues, protégés, and all who considered him a hero; to the men of the Intrepid; to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "870c2895-11d5-4c92-ee5d-6131dd36d303",
        "id": "mHXvHg1T8EYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:156206]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {'ą', '\\x92', 'l', 'L', 'm', 'C', 'é', 'J', \"'\", 'A', 'z', 'r', ';', ')', 'f', 'v', 'c', ':', 'ֹ', 'ָ', '-', 'X', '\\n', ',', '(', 'ç', '.', '”', 'ñ', 'i', 'ó', 'h', '¹', '9', '1', 'd', '8', ']', 'Q', '4', 'I', 'ד', '7', 'U', '+', 'ב', 'í', '“', '%', 'M', 'ּ', 'ï', 'ת', 'O', 'ו', 'q', '$', '¼', 'R', '>', 't', 'j', 'H', 'ł', 'B', 'ô', 'Ó', 'x', '6', 'y', 'ר', 'g', '3', 'e', '<', '&', '[', '2', 'Z', '0', 'à', 'V', 'W', 's', 'è', 'u', '5', 'S', 'á', 'E', '—', 'ה', '–', 'F', 'T', 'n', 'p', 'ę', 'D', 'P', '²', '…', '‘', '*', 'o', 'w', '`', 'Y', '’', 'K', 'k', 'G', ' ', 'b', '/', '?', 'ַ', 'N', '\"', 'a', '!'}\n",
            "Length of Unique characters: 121\n",
            "Number of characters in data: 4224143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "21fa3ff8-3967-466b-927d-b511081894a6",
        "id": "bWJJSNGV8EZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{'ą': 0, '\\x92': 1, 'l': 2, 'L': 3, 'm': 4, 'C': 5, 'é': 6, 'J': 7, \"'\": 8, 'A': 9, 'z': 10, 'r': 11, ';': 12, ')': 13, 'f': 14, 'v': 15, 'c': 16, ':': 17, 'ֹ': 18, 'ָ': 19, '-': 20, 'X': 21, '\\n': 22, ',': 23, '(': 24, 'ç': 25, '.': 26, '”': 27, 'ñ': 28, 'i': 29, 'ó': 30, 'h': 31, '¹': 32, '9': 33, '1': 34, 'd': 35, '8': 36, ']': 37, 'Q': 38, '4': 39, 'I': 40, 'ד': 41, '7': 42, 'U': 43, '+': 44, 'ב': 45, 'í': 46, '“': 47, '%': 48, 'M': 49, 'ּ': 50, 'ï': 51, 'ת': 52, 'O': 53, 'ו': 54, 'q': 55, '$': 56, '¼': 57, 'R': 58, '>': 59, 't': 60, 'j': 61, 'H': 62, 'ł': 63, 'B': 64, 'ô': 65, 'Ó': 66, 'x': 67, '6': 68, 'y': 69, 'ר': 70, 'g': 71, '3': 72, 'e': 73, '<': 74, '&': 75, '[': 76, '2': 77, 'Z': 78, '0': 79, 'à': 80, 'V': 81, 'W': 82, 's': 83, 'è': 84, 'u': 85, '5': 86, 'S': 87, 'á': 88, 'E': 89, '—': 90, 'ה': 91, '–': 92, 'F': 93, 'T': 94, 'n': 95, 'p': 96, 'ę': 97, 'D': 98, 'P': 99, '²': 100, '…': 101, '‘': 102, '*': 103, 'o': 104, 'w': 105, '`': 106, 'Y': 107, '’': 108, 'K': 109, 'k': 110, 'G': 111, ' ': 112, 'b': 113, '/': 114, '?': 115, 'ַ': 116, 'N': 117, '\"': 118, 'a': 119, '!': 120}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UCIhZzf88EZT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8666ff05-c13c-4b7c-a1f2-7f81caa2b4d3",
        "id": "-4v93NVM8EZa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[94, 104, 112, 5, 31, 29, 96, 23, 112, 109, 119, 60, 31, 69, 23, 112, 119, 95, 35, 112, 117, 119, 95, 16, 69, 23, 112, 105, 31, 104, 112, 71, 11, 119, 16, 29, 104, 85, 83, 2, 69, 112, 83, 31, 119, 11, 73, 35, 112, 69, 104, 85, 11, 112, 14, 119, 60, 31, 73, 11, 112, 105, 29, 60, 31, 112, 119, 112, 95, 119, 60, 29, 104, 95, 112, 60, 31, 119, 60, 112, 2, 104, 15, 73, 35, 112, 31, 29, 4, 12, 112, 60, 104, 112, 82, 119, 2, 60, 73, 11] 100 1562\n",
            "[104, 112, 5, 31, 29, 96, 23, 112, 109, 119, 60, 31, 69, 23, 112, 119, 95, 35, 112, 117, 119, 95, 16, 69, 23, 112, 105, 31, 104, 112, 71, 11, 119, 16, 29, 104, 85, 83, 2, 69, 112, 83, 31, 119, 11, 73, 35, 112, 69, 104, 85, 11, 112, 14, 119, 60, 31, 73, 11, 112, 105, 29, 60, 31, 112, 119, 112, 95, 119, 60, 29, 104, 95, 112, 60, 31, 119, 60, 112, 2, 104, 15, 73, 35, 112, 31, 29, 4, 12, 112, 60, 104, 112, 82, 119, 2, 60, 73, 11, 8] 100 1562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "fdd1c992-30a5-4df7-b239-be74f7d012fc",
        "id": "vDq4hHR58EZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: To Chip, Kathy, and Nancy, who graciously shared your father with a nation that loved him; to Walter\n",
            "Output: o Chip, Kathy, and Nancy, who graciously shared your father with a nation that loved him; to Walter'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c_tCxaK-8EZ1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "248b304d-ca0e-4bef-b350-25418018dbcc",
        "id": "pohWxH-v8EaA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (1562, 100, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "00bca707-3c9a-4188-e808-2531a548a5a0",
        "id": "e7ovFPKe8Eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104 112   5  31  29  96  23 112 109 119  60  31  69  23 112 119  95  35\n",
            " 112 117 119  95  16  69  23 112 105  31 104 112  71  11 119  16  29 104\n",
            "  85  83   2  69 112  83  31 119  11  73  35 112  69 104  85  11 112  14\n",
            " 119  60  31  73  11 112 105  29  60  31 112 119 112  95 119  60  29 104\n",
            "  95 112  60  31 119  60 112   2 104  15  73  35 112  31  29   4  12 112\n",
            "  60 104 112  82 119   2  60  73  11   8] (1562, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f5c98265-322b-433a-aed9-7c69f302cf2e",
        "id": "VF-GyLok8Eap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.1)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (1405, 100, 121) (1405, 100)\n",
            "Validation: (157, 100, 121) (157, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zeditssV8EbA",
        "outputId": "5261940c-ec14-4a25-b231-52d5875a4028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(121, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=121, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "X7iYvd2wSVLG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8kRVake08EbK",
        "outputId": "dac4d59e-dd5e-4f32-9584-c377f3536e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.3599... Val Loss: 3.3797\n",
            "Epoch: 2/25... Step: 20... Loss: 3.2334... Val Loss: 3.2278\n",
            "Epoch: 3/25... Step: 30... Loss: 3.1304... Val Loss: 3.1247\n",
            "Epoch: 4/25... Step: 40... Loss: 3.0062... Val Loss: 2.9746\n",
            "Epoch: 5/25... Step: 50... Loss: 2.8495... Val Loss: 2.8118\n",
            "Epoch: 6/25... Step: 60... Loss: 2.7081... Val Loss: 2.6861\n",
            "Epoch: 7/25... Step: 70... Loss: 2.6259... Val Loss: 2.6035\n",
            "Epoch: 8/25... Step: 80... Loss: 2.5572... Val Loss: 2.5328\n",
            "Epoch: 9/25... Step: 90... Loss: 2.4989... Val Loss: 2.4844\n",
            "Epoch: 10/25... Step: 100... Loss: 2.4572... Val Loss: 2.4424\n",
            "Epoch: 11/25... Step: 110... Loss: 2.4115... Val Loss: 2.3982\n",
            "Epoch: 12/25... Step: 120... Loss: 2.3695... Val Loss: 2.3683\n",
            "Epoch: 13/25... Step: 130... Loss: 2.3428... Val Loss: 2.3227\n",
            "Epoch: 14/25... Step: 140... Loss: 2.3032... Val Loss: 2.2976\n",
            "Epoch: 15/25... Step: 150... Loss: 2.2721... Val Loss: 2.2693\n",
            "Epoch: 16/25... Step: 160... Loss: 2.2418... Val Loss: 2.2322\n",
            "Epoch: 17/25... Step: 170... Loss: 2.2034... Val Loss: 2.2085\n",
            "Epoch: 18/25... Step: 180... Loss: 2.1840... Val Loss: 2.1810\n",
            "Epoch: 19/25... Step: 190... Loss: 2.1661... Val Loss: 2.1544\n",
            "Epoch: 20/25... Step: 200... Loss: 2.1350... Val Loss: 2.1331\n",
            "Epoch: 21/25... Step: 210... Loss: 2.1086... Val Loss: 2.1139\n",
            "Epoch: 22/25... Step: 220... Loss: 2.0863... Val Loss: 2.0855\n",
            "Epoch: 23/25... Step: 230... Loss: 2.0662... Val Loss: 2.0650\n",
            "Epoch: 24/25... Step: 240... Loss: 2.0326... Val Loss: 2.0530\n",
            "Epoch: 25/25... Step: 250... Loss: 2.0232... Val Loss: 2.0268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0SXWuo4V8EbW",
        "outputId": "56c6fc12-8b69-44af-ab6b-fe2a83b110c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='and the question i', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "and the question in the workent world are and alded and is orpusiendes of our.  I went the wert thore the comsition ast whil soner wound ass that the cropetill that sumess, of to trear in sorigite and andoricates what a perichong to bela sime of the incustion or that hast to the werner a dorather taking ow and the cane then semund compeniss, and wheren this instreats. That ard war than and whe wand this in our tood..\n",
            "\n",
            "That the sunto warested the stald couringe that will off the proce and will of there way coull cos wis porises to peation treing the promanied to to same aloure thay we came all of a bat ofer it. And that't an this the parined intores worl that world the corming anted the samo a becoramens, the same the carserest we ass are toraling oun theress all the cale to bit intery.\n",
            "\n",
            "In that wall, and it and a tor to to chusire will has on the simus one compence to she those wish a dor on the coustions. And then wist to storman thing will here, wo live ore outhere. It wask to the whis to and wathat and trakes of the cass, the alicans the parsied a diting with to thie sames that to somen to this ande whor to beranes and of orman incenstanion as on whill.  What te se peoplats it the prompronich on out our to a denare stonges. And I wat of oun in the rught the susestich of the worth the contricare, and issare of in arorsince on ore arsunits, a dower ale sumperens a form that it that the what and the pristicing are sonters a cantred our the resesiange our time the ross of challers and of is a placonest and of the strice that ast will have aldoungers in to stoung.  I was the sare the sime this this to se progite and the aro where that what to shas when aro that a whork to to som the well and wall, the wille come to all word and time of thourg the stound becane somere all of the wall the propersion a coltice to batistar of the ase a fout tist of the allioge will, wher proplerads on thas well ceal or this in a semericans the wendition. That's the cans the arsustar offirel can there whore \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rJEuDEKD8Ebd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IddZpNO78H3J"
      },
      "cell_type": "markdown",
      "source": [
        "## TrumpRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d9f934a9-a457-4987-afee-adce4d371c80",
        "id": "tjaYzlaa8H3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/speeches.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read().lower()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "﻿speech 1\n",
            "\n",
            "\n",
            "...thank you so much.  that's so nice.  isn't he a great guy.  he doesn't get a fair pre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b32b4171-453b-474e-f317-9bb35c125bfa",
        "id": "LD63hwm58H36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:496270]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {'h', 'w', 'i', '!', '—', 'g', ' ', 'p', '5', '–', ',', 'n', '8', '-', '?', 'u', '’', '2', '(', ':', ')', 'k', 'o', '9', '0', '$', 'b', 'e', '/', 'y', '\\n', 'v', '6', '=', 'f', '_', '.', '[', 'é', '%', '”', '&', 'q', 'j', '…', 'x', 'c', \"'\", ']', 'a', 's', 'l', 'd', '\\ufeff', ';', 'm', 'r', '4', '“', '3', '‘', '1', 'z', '7', 't', '@', '\"'}\n",
            "Length of Unique characters: 67\n",
            "Number of characters in data: 896270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d4914147-86a0-4d54-9d21-d8229e4212a1",
        "id": "rGgcEUDm8H4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{'h': 0, 'w': 1, 'i': 2, '!': 3, '—': 4, 'g': 5, ' ': 6, 'p': 7, '5': 8, '–': 9, ',': 10, 'n': 11, '8': 12, '-': 13, '?': 14, 'u': 15, '’': 16, '2': 17, '(': 18, ':': 19, ')': 20, 'k': 21, 'o': 22, '9': 23, '0': 24, '$': 25, 'b': 26, 'e': 27, '/': 28, 'y': 29, '\\n': 30, 'v': 31, '6': 32, '=': 33, 'f': 34, '_': 35, '.': 36, '[': 37, 'é': 38, '%': 39, '”': 40, '&': 41, 'q': 42, 'j': 43, '…': 44, 'x': 45, 'c': 46, \"'\": 47, ']': 48, 'a': 49, 's': 50, 'l': 51, 'd': 52, '\\ufeff': 53, ';': 54, 'm': 55, 'r': 56, '4': 57, '“': 58, '3': 59, '‘': 60, '1': 61, 'z': 62, '7': 63, 't': 64, '@': 65, '\"': 66}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RHNZGLnB8H4h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ac0b7e8c-4e97-4b8f-e7e4-744b3ed82665",
        "id": "WnY9vWiC8H4q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[53, 50, 7, 27, 27, 46, 0, 6, 61, 30, 30, 30, 36, 36, 36, 64, 0, 49, 11, 21, 6, 29, 22, 15, 6, 50, 22, 6, 55, 15, 46, 0, 36, 6, 6, 64, 0, 49, 64, 47, 50, 6, 50, 22, 6, 11, 2, 46, 27, 36, 6, 6, 2, 50, 11, 47, 64, 6, 0, 27, 6, 49, 6, 5, 56, 27, 49, 64, 6, 5, 15, 29, 36, 6, 6, 0, 27, 6, 52, 22, 27, 50, 11, 47, 64, 6, 5, 27, 64, 6, 49, 6, 34, 49, 2, 56, 6, 7, 56, 27] 100 4962\n",
            "[50, 7, 27, 27, 46, 0, 6, 61, 30, 30, 30, 36, 36, 36, 64, 0, 49, 11, 21, 6, 29, 22, 15, 6, 50, 22, 6, 55, 15, 46, 0, 36, 6, 6, 64, 0, 49, 64, 47, 50, 6, 50, 22, 6, 11, 2, 46, 27, 36, 6, 6, 2, 50, 11, 47, 64, 6, 0, 27, 6, 49, 6, 5, 56, 27, 49, 64, 6, 5, 15, 29, 36, 6, 6, 0, 27, 6, 52, 22, 27, 50, 11, 47, 64, 6, 5, 27, 64, 6, 49, 6, 34, 49, 2, 56, 6, 7, 56, 27, 50] 100 4962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "efb7079f-5289-4a89-94bf-e7dc078a5721",
        "id": "-QRcANWY8H43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ﻿speech 1\n",
            "\n",
            "\n",
            "...thank you so much.  that's so nice.  isn't he a great guy.  he doesn't get a fair pre\n",
            "Output: speech 1\n",
            "\n",
            "\n",
            "...thank you so much.  that's so nice.  isn't he a great guy.  he doesn't get a fair pres\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DIh9nYuM8H5I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6e004b49-0e5c-464a-a95a-7eeb41bc3b2c",
        "id": "eQNXyuvg8H5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (4962, 100, 67)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "010d3dd1-d1ff-4263-b9d2-85f9eedcfcb4",
        "id": "c4qNFmuB8H5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[50  7 27 27 46  0  6 61 30 30 30 36 36 36 64  0 49 11 21  6 29 22 15  6\n",
            " 50 22  6 55 15 46  0 36  6  6 64  0 49 64 47 50  6 50 22  6 11  2 46 27\n",
            " 36  6  6  2 50 11 47 64  6  0 27  6 49  6  5 56 27 49 64  6  5 15 29 36\n",
            "  6  6  0 27  6 52 22 27 50 11 47 64  6  5 27 64  6 49  6 34 49  2 56  6\n",
            "  7 56 27 50] (4962, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3c745e8f-279a-4699-bb15-7baa4dece8c9",
        "id": "E27_CJ2V8H5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (3969, 100, 67) (3969, 100)\n",
            "Validation: (993, 100, 67) (993, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m6xDn-sb8H6S",
        "outputId": "a7d5f037-1051-4382-aff3-da760d594ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(67, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=67, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "6MJtOScERvI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f6P-S-7s8H6d",
        "outputId": "1c5109fe-50f1-41ab-f3cb-0f4f245cc8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1470
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.2287... Val Loss: 3.1822\n",
            "Epoch: 1/25... Step: 20... Loss: 3.0906... Val Loss: 3.0858\n",
            "Epoch: 1/25... Step: 30... Loss: 2.9882... Val Loss: 2.9710\n",
            "Epoch: 2/25... Step: 40... Loss: 2.8379... Val Loss: 2.8247\n",
            "Epoch: 2/25... Step: 50... Loss: 2.6758... Val Loss: 2.6598\n",
            "Epoch: 2/25... Step: 60... Loss: 2.5457... Val Loss: 2.5285\n",
            "Epoch: 3/25... Step: 70... Loss: 2.4881... Val Loss: 2.4531\n",
            "Epoch: 3/25... Step: 80... Loss: 2.3684... Val Loss: 2.3902\n",
            "Epoch: 3/25... Step: 90... Loss: 2.3475... Val Loss: 2.3347\n",
            "Epoch: 4/25... Step: 100... Loss: 2.3043... Val Loss: 2.2940\n",
            "Epoch: 4/25... Step: 110... Loss: 2.2788... Val Loss: 2.2524\n",
            "Epoch: 4/25... Step: 120... Loss: 2.2056... Val Loss: 2.2205\n",
            "Epoch: 5/25... Step: 130... Loss: 2.2091... Val Loss: 2.1832\n",
            "Epoch: 5/25... Step: 140... Loss: 2.1355... Val Loss: 2.1538\n",
            "Epoch: 5/25... Step: 150... Loss: 2.1225... Val Loss: 2.1275\n",
            "Epoch: 6/25... Step: 160... Loss: 2.0748... Val Loss: 2.0937\n",
            "Epoch: 6/25... Step: 170... Loss: 2.0582... Val Loss: 2.0653\n",
            "Epoch: 6/25... Step: 180... Loss: 2.0627... Val Loss: 2.0367\n",
            "Epoch: 7/25... Step: 190... Loss: 1.9983... Val Loss: 2.0108\n",
            "Epoch: 7/25... Step: 200... Loss: 1.9806... Val Loss: 1.9842\n",
            "Epoch: 7/25... Step: 210... Loss: 1.9857... Val Loss: 1.9624\n",
            "Epoch: 8/25... Step: 220... Loss: 1.9205... Val Loss: 1.9381\n",
            "Epoch: 8/25... Step: 230... Loss: 1.9196... Val Loss: 1.9150\n",
            "Epoch: 8/25... Step: 240... Loss: 1.9163... Val Loss: 1.8986\n",
            "Epoch: 9/25... Step: 250... Loss: 1.8510... Val Loss: 1.8779\n",
            "Epoch: 9/25... Step: 260... Loss: 1.8641... Val Loss: 1.8562\n",
            "Epoch: 9/25... Step: 270... Loss: 1.8491... Val Loss: 1.8438\n",
            "Epoch: 10/25... Step: 280... Loss: 1.7912... Val Loss: 1.8252\n",
            "Epoch: 10/25... Step: 290... Loss: 1.7703... Val Loss: 1.8084\n",
            "Epoch: 10/25... Step: 300... Loss: 1.7666... Val Loss: 1.7876\n",
            "Epoch: 10/25... Step: 310... Loss: 1.7968... Val Loss: 1.7752\n",
            "Epoch: 11/25... Step: 320... Loss: 1.7356... Val Loss: 1.7627\n",
            "Epoch: 11/25... Step: 330... Loss: 1.7429... Val Loss: 1.7477\n",
            "Epoch: 11/25... Step: 340... Loss: 1.7130... Val Loss: 1.7356\n",
            "Epoch: 12/25... Step: 350... Loss: 1.6632... Val Loss: 1.7218\n",
            "Epoch: 12/25... Step: 360... Loss: 1.6802... Val Loss: 1.7064\n",
            "Epoch: 12/25... Step: 370... Loss: 1.6802... Val Loss: 1.6925\n",
            "Epoch: 13/25... Step: 380... Loss: 1.7231... Val Loss: 1.6821\n",
            "Epoch: 13/25... Step: 390... Loss: 1.6301... Val Loss: 1.6711\n",
            "Epoch: 13/25... Step: 400... Loss: 1.6621... Val Loss: 1.6606\n",
            "Epoch: 14/25... Step: 410... Loss: 1.6411... Val Loss: 1.6485\n",
            "Epoch: 14/25... Step: 420... Loss: 1.6290... Val Loss: 1.6377\n",
            "Epoch: 14/25... Step: 430... Loss: 1.5905... Val Loss: 1.6315\n",
            "Epoch: 15/25... Step: 440... Loss: 1.6037... Val Loss: 1.6248\n",
            "Epoch: 15/25... Step: 450... Loss: 1.5596... Val Loss: 1.6117\n",
            "Epoch: 15/25... Step: 460... Loss: 1.5647... Val Loss: 1.6038\n",
            "Epoch: 16/25... Step: 470... Loss: 1.5749... Val Loss: 1.5964\n",
            "Epoch: 16/25... Step: 480... Loss: 1.5541... Val Loss: 1.5915\n",
            "Epoch: 16/25... Step: 490... Loss: 1.5596... Val Loss: 1.5808\n",
            "Epoch: 17/25... Step: 500... Loss: 1.5001... Val Loss: 1.5750\n",
            "Epoch: 17/25... Step: 510... Loss: 1.5319... Val Loss: 1.5710\n",
            "Epoch: 17/25... Step: 520... Loss: 1.5522... Val Loss: 1.5521\n",
            "Epoch: 18/25... Step: 530... Loss: 1.4924... Val Loss: 1.5551\n",
            "Epoch: 18/25... Step: 540... Loss: 1.5063... Val Loss: 1.5462\n",
            "Epoch: 18/25... Step: 550... Loss: 1.5005... Val Loss: 1.5425\n",
            "Epoch: 19/25... Step: 560... Loss: 1.4485... Val Loss: 1.5332\n",
            "Epoch: 19/25... Step: 570... Loss: 1.4771... Val Loss: 1.5247\n",
            "Epoch: 19/25... Step: 580... Loss: 1.4859... Val Loss: 1.5217\n",
            "Epoch: 20/25... Step: 590... Loss: 1.4158... Val Loss: 1.5170\n",
            "Epoch: 20/25... Step: 600... Loss: 1.4212... Val Loss: 1.5069\n",
            "Epoch: 20/25... Step: 610... Loss: 1.4314... Val Loss: 1.5053\n",
            "Epoch: 20/25... Step: 620... Loss: 1.4577... Val Loss: 1.4990\n",
            "Epoch: 21/25... Step: 630... Loss: 1.4266... Val Loss: 1.4933\n",
            "Epoch: 21/25... Step: 640... Loss: 1.4182... Val Loss: 1.4894\n",
            "Epoch: 21/25... Step: 650... Loss: 1.3987... Val Loss: 1.4883\n",
            "Epoch: 22/25... Step: 660... Loss: 1.3768... Val Loss: 1.4828\n",
            "Epoch: 22/25... Step: 670... Loss: 1.4048... Val Loss: 1.4749\n",
            "Epoch: 22/25... Step: 680... Loss: 1.4087... Val Loss: 1.4721\n",
            "Epoch: 23/25... Step: 690... Loss: 1.4493... Val Loss: 1.4679\n",
            "Epoch: 23/25... Step: 700... Loss: 1.3658... Val Loss: 1.4623\n",
            "Epoch: 23/25... Step: 710... Loss: 1.3845... Val Loss: 1.4633\n",
            "Epoch: 24/25... Step: 720... Loss: 1.3771... Val Loss: 1.4606\n",
            "Epoch: 24/25... Step: 730... Loss: 1.3838... Val Loss: 1.4547\n",
            "Epoch: 24/25... Step: 740... Loss: 1.3696... Val Loss: 1.4553\n",
            "Epoch: 25/25... Step: 750... Loss: 1.3744... Val Loss: 1.4491\n",
            "Epoch: 25/25... Step: 760... Loss: 1.3414... Val Loss: 1.4485\n",
            "Epoch: 25/25... Step: 770... Loss: 1.3467... Val Loss: 1.4434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-0uL9IPZ8H6p",
        "outputId": "5c7653c2-570f-416a-fb8e-3f5114798014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='fake news', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fake news immigration is trump to be a sprescibe to talk and we have got to see what i’m doing is they statting the wert ago.\n",
            "and they’re not comerang and tell you, and it’s not a creat startest this is a border of mane is almest so incredible again. we had a toter change, and to say the world where it is to get and they don’t know.\n",
            "we have to go ialo. i see the some if i were with the thill believe when i was showling, and they are going to be some of them to do this.\n",
            "\n",
            "\n",
            "and if you can did that he don’t win. it’s a contratelley that’s has bigger. but here, we’re going to stopy isis backed a letter and the well. i’ll be the special i think that we have a seecial parts of middle east.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "and i went in with mover of television, is a courle people to do what they’re going to be saying it’s not.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "thank you very group. it’s a love all oversite, we have to start the wart our military is a besa fight of them. i’m not going to do a lot of people. i didn’t thoug this and we’re going to be and say with the more country. you know, we will say \"had is the there.\n",
            "\n",
            "\n",
            "we won americans and all of the world, it with these problems. you have to be a couple of china. it will be able. and i have to say a deal, take coure of instations, and i said it, and all of it. think of the many paiss to do with trump of and i want a suppresiate to be and she was brad problem. i would have saying \"on expeople american taxis against millions, it can tell you it. we cent is them. and they did worse. what we have terration and some of the mexico are talking obamacaugher. i have brean shorle.\n",
            "i have the want to done time with the many. we’re going to have to stop is something.\" that is the bad.\n",
            "stere are i to take time. we can’t let able of the wise amazing.\n",
            "and they have a communities chose. that’s not going to win. i heard to build is intrade. and the way what don’t win on the stote that i will be saying this support. and i’m the gay. i said \"oh, a lot of people is serong inthers to taxes, where we have \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gyy73AcF8H6w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AnVVUlh-8QVM"
      },
      "cell_type": "markdown",
      "source": [
        "## AnnaRNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c7a7621f-5cc5-4e77-ac0f-b70b63fc9fc4",
        "id": "oc0eKK6S8QVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = 'data/anna.txt'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "  \n",
        "    data = f.read().lower()\n",
        "    \n",
        "print ('First 200 characters of data\\n')\n",
        "print (data[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 200 characters of data\n",
            "\n",
            "chapter 1\n",
            "\n",
            "\n",
            "happy families are all alike; every unhappy family is unhappy in its own\n",
            "way.\n",
            "\n",
            "everything was in confusion in the oblonskys' house. the wife had\n",
            "discovered that the husband was carrying on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "cb0136e9-36f7-42e8-c049-f27c0d615d09",
        "id": "p5v_S4je8QV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# unique characters in dataset and its count\n",
        "chars = set(data)\n",
        "vocab_size = len(set(data))\n",
        "data_size = len(data)\n",
        "print ('Unique characters:', chars)\n",
        "print ('Length of Unique characters:', vocab_size)\n",
        "print ('Number of characters in data:', data_size)\n",
        "\n",
        "#restricting so that we can load all data onto RAM\n",
        "#uncomment this line to run on all data\n",
        "data = data[:585223]\n",
        "data_size = len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique characters: {';', 'a', '`', 'q', '5', '4', 'v', '0', '-', 'd', 'c', 'm', '2', ',', 'b', '6', 'r', ')', 'u', '1', 'l', 'x', 'i', 'f', 's', '?', ':', 'y', '(', '_', ' ', 'z', '8', 'g', \"'\", 'e', '9', '.', '!', '\"', '3', 'n', '\\n', 'o', 'h', 'p', 't', 'j', '7', 'w', 'k'}\n",
            "Length of Unique characters: 51\n",
            "Number of characters in data: 985223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1c24d43e-0ce7-40e5-cf39-3779ecde5a69",
        "id": "xTq89ZSn8QWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "char2id = {ch:i for i, ch in enumerate(chars)}\n",
        "id2char = {i:ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print ('Characters to id\\n')\n",
        "print (char2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters to id\n",
            "\n",
            "{';': 0, 'a': 1, '`': 2, 'q': 3, '5': 4, '4': 5, 'v': 6, '0': 7, '-': 8, 'd': 9, 'c': 10, 'm': 11, '2': 12, ',': 13, 'b': 14, '6': 15, 'r': 16, ')': 17, 'u': 18, '1': 19, 'l': 20, 'x': 21, 'i': 22, 'f': 23, 's': 24, '?': 25, ':': 26, 'y': 27, '(': 28, '_': 29, ' ': 30, 'z': 31, '8': 32, 'g': 33, \"'\": 34, 'e': 35, '9': 36, '.': 37, '!': 38, '\"': 39, '3': 40, 'n': 41, '\\n': 42, 'o': 43, 'h': 44, 'p': 45, 't': 46, 'j': 47, '7': 48, 'w': 49, 'k': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tD6-Unq-8QWl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cut the text into fixed size inputs of length maxlen\n",
        "maxlen = 100\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "end = data_size - maxlen\n",
        "for i in range(0, end, maxlen):\n",
        "    sentences.append([char2id[ch] for ch in data[i : i+maxlen]])\n",
        "    next_chars.append([char2id[ch] for ch in data[i+1: i+maxlen+1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "96425be9-d56c-4e0c-8906-b58d0b19850e",
        "id": "PR_9hgTB8QWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print (sentences[0], len(sentences[0]), len(sentences))\n",
        "print (next_chars[0], len(next_chars[0]), len(next_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10, 44, 1, 45, 46, 35, 16, 30, 19, 42, 42, 42, 44, 1, 45, 45, 27, 30, 23, 1, 11, 22, 20, 22, 35, 24, 30, 1, 16, 35, 30, 1, 20, 20, 30, 1, 20, 22, 50, 35, 0, 30, 35, 6, 35, 16, 27, 30, 18, 41, 44, 1, 45, 45, 27, 30, 23, 1, 11, 22, 20, 27, 30, 22, 24, 30, 18, 41, 44, 1, 45, 45, 27, 30, 22, 41, 30, 22, 46, 24, 30, 43, 49, 41, 42, 49, 1, 27, 37, 42, 42, 35, 6, 35, 16, 27, 46, 44, 22, 41] 100 5852\n",
            "[44, 1, 45, 46, 35, 16, 30, 19, 42, 42, 42, 44, 1, 45, 45, 27, 30, 23, 1, 11, 22, 20, 22, 35, 24, 30, 1, 16, 35, 30, 1, 20, 20, 30, 1, 20, 22, 50, 35, 0, 30, 35, 6, 35, 16, 27, 30, 18, 41, 44, 1, 45, 45, 27, 30, 23, 1, 11, 22, 20, 27, 30, 22, 24, 30, 18, 41, 44, 1, 45, 45, 27, 30, 22, 41, 30, 22, 46, 24, 30, 43, 49, 41, 42, 49, 1, 27, 37, 42, 42, 35, 6, 35, 16, 27, 46, 44, 22, 41, 33] 100 5852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8a1a11fd-7c54-473a-8b7c-45a22dc4985b",
        "id": "ka9k8GZD8QW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "print ('Input:', ''.join(id2char[i] for i in sentences[0]))\n",
        "print ('Output:', ''.join(id2char[i] for i in next_chars[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: chapter 1\n",
            "\n",
            "\n",
            "happy families are all alike; every unhappy family is unhappy in its own\n",
            "way.\n",
            "\n",
            "everythin\n",
            "Output: hapter 1\n",
            "\n",
            "\n",
            "happy families are all alike; every unhappy family is unhappy in its own\n",
            "way.\n",
            "\n",
            "everything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7GBDIiMl8QXW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='float32')[y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f6530831-6780-46a6-c1fa-9ab5b447c3fa",
        "id": "fBX8zcdM8QXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.float32)\n",
        "one_hot = [to_categorical(c, num_classes=vocab_size) for i in range(len(sentences)) for c in sentences[i]]\n",
        "X = np.array(one_hot).reshape(X.shape)\n",
        "print (X[0], X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (5852, 100, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9ba8d35a-c22b-4df4-85ee-f9c5dd51272e",
        "id": "Ovr7Y91f8QYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "Y = np.zeros((len(next_chars), maxlen), dtype=np.float32)\n",
        "Y = np.array(next_chars).reshape(Y.shape)\n",
        "print (Y[0], Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[44  1 45 46 35 16 30 19 42 42 42 44  1 45 45 27 30 23  1 11 22 20 22 35\n",
            " 24 30  1 16 35 30  1 20 20 30  1 20 22 50 35  0 30 35  6 35 16 27 30 18\n",
            " 41 44  1 45 45 27 30 23  1 11 22 20 27 30 22 24 30 18 41 44  1 45 45 27\n",
            " 30 22 41 30 22 46 24 30 43 49 41 42 49  1 27 37 42 42 35  6 35 16 27 46\n",
            " 44 22 41 33] (5852, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "dfb74ef3-7d4c-446c-9f47-d00ae671f095",
        "id": "r7zEwwmr8QYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2)\n",
        "print ('Training:', train_x.shape, train_y.shape)\n",
        "print ('Validation:', val_x.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (4681, 100, 51) (4681, 100)\n",
            "Validation: (1171, 100, 51) (1171, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p3yHgpfY8QYr",
        "outputId": "9d169bee-52b0-433e-de6a-9898a4e52846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "net = CharRNN(n_hidden=512, n_layers=2)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (lstm): LSTM(51, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=51, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "AMArMZVoR1MN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2AiCKO9G8QY9",
        "outputId": "badedced-99bc-4ad9-f69c-8d9b4a0eb441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1708
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, train_x, train_y, val_x, val_y, opt=opt, criterion=criterion, epochs=25,\n",
        "      batch_size=128, maxlen=100, clip=5, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Step: 10... Loss: 3.1530... Val Loss: 3.1431\n",
            "Epoch: 1/25... Step: 20... Loss: 3.0492... Val Loss: 3.0508\n",
            "Epoch: 1/25... Step: 30... Loss: 2.9280... Val Loss: 2.9294\n",
            "Epoch: 2/25... Step: 40... Loss: 2.7354... Val Loss: 2.7629\n",
            "Epoch: 2/25... Step: 50... Loss: 2.6036... Val Loss: 2.6110\n",
            "Epoch: 2/25... Step: 60... Loss: 2.5185... Val Loss: 2.5182\n",
            "Epoch: 2/25... Step: 70... Loss: 2.4501... Val Loss: 2.4556\n",
            "Epoch: 3/25... Step: 80... Loss: 2.3872... Val Loss: 2.4131\n",
            "Epoch: 3/25... Step: 90... Loss: 2.3642... Val Loss: 2.3764\n",
            "Epoch: 3/25... Step: 100... Loss: 2.3246... Val Loss: 2.3413\n",
            "Epoch: 4/25... Step: 110... Loss: 2.3332... Val Loss: 2.3079\n",
            "Epoch: 4/25... Step: 120... Loss: 2.2664... Val Loss: 2.2792\n",
            "Epoch: 4/25... Step: 130... Loss: 2.2599... Val Loss: 2.2588\n",
            "Epoch: 4/25... Step: 140... Loss: 2.2387... Val Loss: 2.2247\n",
            "Epoch: 5/25... Step: 150... Loss: 2.2071... Val Loss: 2.2088\n",
            "Epoch: 5/25... Step: 160... Loss: 2.1550... Val Loss: 2.1776\n",
            "Epoch: 5/25... Step: 170... Loss: 2.1398... Val Loss: 2.1506\n",
            "Epoch: 5/25... Step: 180... Loss: 2.0915... Val Loss: 2.1285\n",
            "Epoch: 6/25... Step: 190... Loss: 2.1023... Val Loss: 2.1043\n",
            "Epoch: 6/25... Step: 200... Loss: 2.0753... Val Loss: 2.0842\n",
            "Epoch: 6/25... Step: 210... Loss: 2.0370... Val Loss: 2.0601\n",
            "Epoch: 7/25... Step: 220... Loss: 1.9833... Val Loss: 2.0429\n",
            "Epoch: 7/25... Step: 230... Loss: 2.0106... Val Loss: 2.0227\n",
            "Epoch: 7/25... Step: 240... Loss: 1.9633... Val Loss: 2.0061\n",
            "Epoch: 7/25... Step: 250... Loss: 1.9893... Val Loss: 1.9879\n",
            "Epoch: 8/25... Step: 260... Loss: 1.9223... Val Loss: 1.9774\n",
            "Epoch: 8/25... Step: 270... Loss: 1.9334... Val Loss: 1.9532\n",
            "Epoch: 8/25... Step: 280... Loss: 1.9062... Val Loss: 1.9429\n",
            "Epoch: 9/25... Step: 290... Loss: 1.9473... Val Loss: 1.9238\n",
            "Epoch: 9/25... Step: 300... Loss: 1.8835... Val Loss: 1.9111\n",
            "Epoch: 9/25... Step: 310... Loss: 1.8991... Val Loss: 1.8974\n",
            "Epoch: 9/25... Step: 320... Loss: 1.8797... Val Loss: 1.8847\n",
            "Epoch: 10/25... Step: 330... Loss: 1.8530... Val Loss: 1.8717\n",
            "Epoch: 10/25... Step: 340... Loss: 1.8306... Val Loss: 1.8561\n",
            "Epoch: 10/25... Step: 350... Loss: 1.7954... Val Loss: 1.8444\n",
            "Epoch: 10/25... Step: 360... Loss: 1.7865... Val Loss: 1.8373\n",
            "Epoch: 11/25... Step: 370... Loss: 1.8017... Val Loss: 1.8264\n",
            "Epoch: 11/25... Step: 380... Loss: 1.7939... Val Loss: 1.8171\n",
            "Epoch: 11/25... Step: 390... Loss: 1.7686... Val Loss: 1.8064\n",
            "Epoch: 12/25... Step: 400... Loss: 1.7314... Val Loss: 1.7977\n",
            "Epoch: 12/25... Step: 410... Loss: 1.7510... Val Loss: 1.7853\n",
            "Epoch: 12/25... Step: 420... Loss: 1.7339... Val Loss: 1.7786\n",
            "Epoch: 12/25... Step: 430... Loss: 1.7576... Val Loss: 1.7699\n",
            "Epoch: 13/25... Step: 440... Loss: 1.6858... Val Loss: 1.7657\n",
            "Epoch: 13/25... Step: 450... Loss: 1.7081... Val Loss: 1.7534\n",
            "Epoch: 13/25... Step: 460... Loss: 1.6974... Val Loss: 1.7422\n",
            "Epoch: 14/25... Step: 470... Loss: 1.7282... Val Loss: 1.7416\n",
            "Epoch: 14/25... Step: 480... Loss: 1.6662... Val Loss: 1.7330\n",
            "Epoch: 14/25... Step: 490... Loss: 1.7097... Val Loss: 1.7247\n",
            "Epoch: 14/25... Step: 500... Loss: 1.6690... Val Loss: 1.7162\n",
            "Epoch: 15/25... Step: 510... Loss: 1.6585... Val Loss: 1.7093\n",
            "Epoch: 15/25... Step: 520... Loss: 1.6563... Val Loss: 1.6990\n",
            "Epoch: 15/25... Step: 530... Loss: 1.6316... Val Loss: 1.6940\n",
            "Epoch: 15/25... Step: 540... Loss: 1.6230... Val Loss: 1.6930\n",
            "Epoch: 16/25... Step: 550... Loss: 1.6215... Val Loss: 1.6796\n",
            "Epoch: 16/25... Step: 560... Loss: 1.6472... Val Loss: 1.6794\n",
            "Epoch: 16/25... Step: 570... Loss: 1.6156... Val Loss: 1.6717\n",
            "Epoch: 17/25... Step: 580... Loss: 1.5727... Val Loss: 1.6691\n",
            "Epoch: 17/25... Step: 590... Loss: 1.5863... Val Loss: 1.6593\n",
            "Epoch: 17/25... Step: 600... Loss: 1.5669... Val Loss: 1.6570\n",
            "Epoch: 17/25... Step: 610... Loss: 1.6144... Val Loss: 1.6513\n",
            "Epoch: 18/25... Step: 620... Loss: 1.5618... Val Loss: 1.6477\n",
            "Epoch: 18/25... Step: 630... Loss: 1.5638... Val Loss: 1.6402\n",
            "Epoch: 18/25... Step: 640... Loss: 1.5623... Val Loss: 1.6319\n",
            "Epoch: 19/25... Step: 650... Loss: 1.5834... Val Loss: 1.6368\n",
            "Epoch: 19/25... Step: 660... Loss: 1.5311... Val Loss: 1.6285\n",
            "Epoch: 19/25... Step: 670... Loss: 1.5783... Val Loss: 1.6251\n",
            "Epoch: 19/25... Step: 680... Loss: 1.5481... Val Loss: 1.6164\n",
            "Epoch: 20/25... Step: 690... Loss: 1.5340... Val Loss: 1.6160\n",
            "Epoch: 20/25... Step: 700... Loss: 1.5370... Val Loss: 1.6140\n",
            "Epoch: 20/25... Step: 710... Loss: 1.5197... Val Loss: 1.6129\n",
            "Epoch: 20/25... Step: 720... Loss: 1.5052... Val Loss: 1.6068\n",
            "Epoch: 21/25... Step: 730... Loss: 1.5217... Val Loss: 1.6023\n",
            "Epoch: 21/25... Step: 740... Loss: 1.5322... Val Loss: 1.5981\n",
            "Epoch: 21/25... Step: 750... Loss: 1.5068... Val Loss: 1.5939\n",
            "Epoch: 22/25... Step: 760... Loss: 1.4750... Val Loss: 1.5961\n",
            "Epoch: 22/25... Step: 770... Loss: 1.4858... Val Loss: 1.5941\n",
            "Epoch: 22/25... Step: 780... Loss: 1.4797... Val Loss: 1.5901\n",
            "Epoch: 22/25... Step: 790... Loss: 1.5094... Val Loss: 1.5862\n",
            "Epoch: 23/25... Step: 800... Loss: 1.4661... Val Loss: 1.5839\n",
            "Epoch: 23/25... Step: 810... Loss: 1.4677... Val Loss: 1.5810\n",
            "Epoch: 23/25... Step: 820... Loss: 1.4629... Val Loss: 1.5701\n",
            "Epoch: 24/25... Step: 830... Loss: 1.5025... Val Loss: 1.5691\n",
            "Epoch: 24/25... Step: 840... Loss: 1.4482... Val Loss: 1.5678\n",
            "Epoch: 24/25... Step: 850... Loss: 1.4856... Val Loss: 1.5637\n",
            "Epoch: 24/25... Step: 860... Loss: 1.4550... Val Loss: 1.5630\n",
            "Epoch: 25/25... Step: 870... Loss: 1.4473... Val Loss: 1.5612\n",
            "Epoch: 25/25... Step: 880... Loss: 1.4516... Val Loss: 1.5646\n",
            "Epoch: 25/25... Step: 890... Loss: 1.4412... Val Loss: 1.5572\n",
            "Epoch: 25/25... Step: 900... Loss: 1.4177... Val Loss: 1.5640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tDwWFGtu8QZI",
        "outputId": "8e7517cf-2a83-47a0-8c86-9e7b69b0c534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "print(sample(net, 2000, prime='anna', top_k=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "anna, his chear, and was at his brother, she sat down the forts of a force that his cales was straight for his beginning to her sore, a sittle of\n",
            "it, but at some tell the paits.\n",
            "\n",
            "\"you want it,\" said stepan arkadyevitch.\n",
            "\n",
            "\"what i had be noter with the morning. the conversation was stord out him a fore an her atiently in the\n",
            "some and she had\n",
            "been delighted up the door, stepan arkadyevitch was some at her.\n",
            "\n",
            "\"oh, then well i down the pression of her hand out the canter with the\n",
            "dinner as all her has should and saw that her sat her hand, and his hands. \"as they way, too,\" alexey alexandrovitch was she was\n",
            "askandary the came to asking him a lift a charg, and still he would have so that the masche stand in his was strought. the same\n",
            "on the success of to the princess had to been to the sof the should\n",
            "hand to the pland was a find of compare and hulding\n",
            "towards the conter he had been all at the set that when the sare horses of a shame stirlly was simply stoom the talker had been down that she was not considered his\n",
            "face, and still answer and her his hinds of the\n",
            "care to the\n",
            "masters, and had\n",
            "boench she does the pronic of streaking\n",
            "a smiling, before she went up to the bouther to the\n",
            "carriage. \"i didn't understand that word i have thought that he could not say the\n",
            "sone, and she was not\n",
            "in his ball was a forg will to\n",
            "the thought, and with a cale, and he was the tall made a sone, and they was a fathing and she clushed to see her face of the\n",
            "praning with the contic about her strenkeres. they were stepan arkadyevitch asked the\n",
            "carriage with head at them. the cortain the different of a proplating tater, wanting to him, and has been stood her hand there assitch he was, she had\n",
            "nothed and woman, and he was something that he had not see into the\n",
            "princess\n",
            "would have had been the mare were anna arkadyevna when an the carries.\n",
            "\n",
            "\"well, and i should have been in home time, and that's than?\" i'm a mome one. i she was as something tasking of anow,\" she was to conce an her hand to mean, went up to h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDwjphbR8QZP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}